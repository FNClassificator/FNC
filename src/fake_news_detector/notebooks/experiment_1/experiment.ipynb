{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Classify with `dataset_style.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils import io\n",
    "from src.fake_news_detector.core.classificators import LDA, QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import style dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/dataset_style.json')\n",
    "df = pd.DataFrame(data=articles['articles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two = df[['mean_words_per_sentence', 'pert_total_nouns', 'n_words', 'title_n_words', 'title_sentiment' ]]\n",
    "df_two['fake'] = df['fake']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_words_per_sentence</th>\n",
       "      <th>pert_total_nouns</th>\n",
       "      <th>n_words</th>\n",
       "      <th>title_n_words</th>\n",
       "      <th>title_sentiment</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.521569</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>255</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.840456</td>\n",
       "      <td>0.321937</td>\n",
       "      <td>351</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.285106</td>\n",
       "      <td>0.310638</td>\n",
       "      <td>235</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.120000</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>125</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.6202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.536232</td>\n",
       "      <td>0.311594</td>\n",
       "      <td>138</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_words_per_sentence  pert_total_nouns  n_words  title_n_words  \\\n",
       "0                 4.521569          0.356863      255             10   \n",
       "1                 4.840456          0.321937      351             12   \n",
       "2                 4.285106          0.310638      235             14   \n",
       "3                 4.120000          0.272000      125             12   \n",
       "4                 4.536232          0.311594      138             12   \n",
       "\n",
       "   title_sentiment  fake  \n",
       "0          -0.5719     1  \n",
       "1          -0.1027     1  \n",
       "2          -0.4588     1  \n",
       "3          -0.6202     1  \n",
       "4          -0.4767     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_words_per_sentence</th>\n",
       "      <th>pert_total_nouns</th>\n",
       "      <th>n_words</th>\n",
       "      <th>title_n_words</th>\n",
       "      <th>title_sentiment</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4.811947</td>\n",
       "      <td>0.318584</td>\n",
       "      <td>452</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.624390</td>\n",
       "      <td>0.290244</td>\n",
       "      <td>410</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.7845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.601695</td>\n",
       "      <td>0.266949</td>\n",
       "      <td>236</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.162651</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>166</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.262570</td>\n",
       "      <td>0.310056</td>\n",
       "      <td>358</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.6908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_words_per_sentence  pert_total_nouns  n_words  title_n_words  \\\n",
       "89                 4.811947          0.318584      452              6   \n",
       "26                 4.624390          0.290244      410              8   \n",
       "42                 4.601695          0.266949      236             10   \n",
       "70                 5.162651          0.379518      166             13   \n",
       "15                 4.262570          0.310056      358              9   \n",
       "\n",
       "    title_sentiment  fake  \n",
       "89           0.0000     0  \n",
       "26          -0.7845     1  \n",
       "42          -0.1027     1  \n",
       "70          -0.1280     0  \n",
       "15          -0.6908     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO SPLIT DF\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_two, test_size=0.2, random_state=42)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(model,df_train, df_test, labels_x, label_tag, scaler, type_m):\n",
    "    print('For labels:', ', '.join(labels_x))\n",
    "    if type_m == 'LDA':\n",
    "        pred = LDA.run_performance(model,  df_train[labels_x], df_train[label_tag], df_test[labels_x], df_test[label_tag], scaler)\n",
    "    else:\n",
    "        pred = QDA.run_performance(model,  df_train[labels_x], df_train[label_tag], df_test[labels_x], df_test[label_tag], scaler)\n",
    "    return pred\n",
    "        \n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For labels: pert_total_nouns, n_words, title_sentiment\n",
      "Confusion matrix:\n",
      "[[ 6  2]\n",
      " [ 2 11]]\n",
      "REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.85      0.85      0.85        13\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        21\n",
      "   macro avg       0.80      0.80      0.80        21\n",
      "weighted avg       0.81      0.81      0.81        21\n",
      "\n",
      "Train precision score: 0.75\n",
      "Test precision score: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "n_components = 1\n",
    "scaler = True\n",
    "lda_model = LDA.create_LDA_model(n_components) # Create\n",
    "labels_x = ['pert_total_nouns', 'n_words',  'title_sentiment']\n",
    "res = do_test(lda_model, df_train, df_test,labels_x, 'fake', scaler, 'LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For labels: pert_total_nouns, n_words, title_sentiment, title_n_words, mean_words_per_sentence\n",
      "Confusion matrix:\n",
      "[[ 5  3]\n",
      " [ 2 11]]\n",
      "REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67         8\n",
      "           1       0.79      0.85      0.81        13\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        21\n",
      "   macro avg       0.75      0.74      0.74        21\n",
      "weighted avg       0.76      0.76      0.76        21\n",
      "\n",
      "Train precision score: 0.7875\n",
      "Test precision score: 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "labels_x = ['pert_total_nouns','n_words', 'title_sentiment', 'title_n_words', 'mean_words_per_sentence']\n",
    "res = do_test(lda_model, df_train, df_test,labels_x, 'fake', scaler, 'LDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For labels: pert_total_nouns, n_words, title_sentiment\n",
      "Confusion matrix:\n",
      "[[ 6  2]\n",
      " [ 2 11]]\n",
      "REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.85      0.85      0.85        13\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        21\n",
      "   macro avg       0.80      0.80      0.80        21\n",
      "weighted avg       0.81      0.81      0.81        21\n",
      "\n",
      "Train precision score: 0.75\n",
      "Test precision score: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "scaler = True\n",
    "qda_model = QDA.create_QDA_model() # Create\n",
    "labels_x = ['pert_total_nouns', 'n_words',  'title_sentiment']\n",
    "res = do_test(qda_model, df_train, df_test,labels_x, 'fake', scaler, 'QDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For labels: pert_total_nouns, n_words, title_sentiment, title_n_words, mean_words_per_sentence\n",
      "Confusion matrix:\n",
      "[[ 4  4]\n",
      " [ 1 12]]\n",
      "REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62         8\n",
      "           1       0.75      0.92      0.83        13\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        21\n",
      "   macro avg       0.78      0.71      0.72        21\n",
      "weighted avg       0.77      0.76      0.75        21\n",
      "\n",
      "Train precision score: 0.775\n",
      "Test precision score: 0.75\n"
     ]
    }
   ],
   "source": [
    "labels_x = ['pert_total_nouns','n_words', 'title_sentiment', 'title_n_words', 'mean_words_per_sentence']\n",
    "res = do_test(qda_model, df_train, df_test,labels_x, 'fake', scaler, 'QDA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
