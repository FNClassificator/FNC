{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6: TF-IDF + DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.utils import io\n",
    "\n",
    "from src.fake_news_detector.core.encoders import tfidf_helpers as tf \n",
    "from src.fake_news_detector.core.classificators import SupportVectorMachine as svm_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import `dataset_content.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/dataset_content.json')\n",
    "df = pd.DataFrame(data=articles['articles']) # Put in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_lists(dataset, word_lists):\n",
    "    result = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        text_join = \"\"\n",
    "        for feature in word_lists:\n",
    "            doc_list = row[feature]\n",
    "            text_join += ' '.join(doc_list)\n",
    "        result.append(text_join)\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>find corpse vegetarian restaurant Bangkok find...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>switzerland warn authorize extradition politic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>navarre censor Songs Amaral Shakira song Madma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>woman pretend blind years greet people Now tru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrested ejaculate boss coffee last four years...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  find corpse vegetarian restaurant Bangkok find...      1\n",
       "1  switzerland warn authorize extradition politic...      1\n",
       "2  navarre censor Songs Amaral Shakira song Madma...      1\n",
       "3  woman pretend blind years greet people Now tru...      1\n",
       "4  arrested ejaculate boss coffee last four years...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame()\n",
    "dataset['text'] = join_lists(df, ['all_word'])\n",
    "dataset['label'] = df['fake']*1\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 6713)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv_values = cv.fit_transform(dataset['text'].values)\n",
    "cv_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split datasets in real and false\n",
    "df_train_real = df_train.loc[df_train['label'] == 0]\n",
    "df_train_fake = df_train.loc[df_train['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 6713) (57, 6713)\n"
     ]
    }
   ],
   "source": [
    "# 2. Transform each group from text to vocabulary\n",
    "cv_train_real = cv.transform(df_train_real['text'])\n",
    "cv_train_fake = cv.transform(df_train_fake['text'])\n",
    "print(cv_train_real.shape,cv_train_fake.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create TF-IDF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create models for each\n",
    "tfidf_model_real = TfidfTransformer(use_idf=True).fit(cv_train_real)\n",
    "tfidf_model_fake = TfidfTransformer(use_idf=True).fit(cv_train_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Fake news relevant words\n",
    "We want to get the top relevant words of Fake News documents by the TF-IDF create, so we compute from fake news text to tfidf weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_words_fake_train = tfidf_model_fake.transform(cv_train_fake)\n",
    "results_fake, top_fake_words = tf.get_topn_relevant_words(cv, tf_words_fake_train, topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rice': 0.689,\n",
       " 'cheese': 0.637,\n",
       " 'dog': 0.624,\n",
       " 'restaurant': 0.5,\n",
       " 'ikea': 0.5,\n",
       " 'switzerland': 0.481,\n",
       " 'crocodiles': 0.48,\n",
       " 'sexual': 0.458,\n",
       " 'foreign': 0.442,\n",
       " 'songs': 0.438,\n",
       " 'cor': 0.435,\n",
       " 'wax': 0.428,\n",
       " 'guitar': 0.424,\n",
       " 'day': 0.155,\n",
       " 'water': 0.152,\n",
       " 'beach': 0.41,\n",
       " 'echenique': 0.41,\n",
       " 'libya': 0.409,\n",
       " 'semen': 0.405,\n",
       " 'store': 0.4,\n",
       " 'prisoners': 0.379,\n",
       " 'alejandro': 0.395,\n",
       " 'blind': 0.39,\n",
       " 'museum': 0.385,\n",
       " 'pastor': 0.384,\n",
       " 'cold': 0.383,\n",
       " 'women': 0.202,\n",
       " 'drivers': 0.192,\n",
       " 'use': 0.149,\n",
       " 'military': 0.373,\n",
       " 'crush': 0.371,\n",
       " 'feminist': 0.37,\n",
       " 'ugly': 0.368,\n",
       " 'pp': 0.366,\n",
       " 'guindos': 0.36,\n",
       " 'melilla': 0.359,\n",
       " 'police': 0.153,\n",
       " 'forest': 0.355,\n",
       " 'minimum': 0.354,\n",
       " 'control': 0.206,\n",
       " 'vallecas': 0.346,\n",
       " 'office': 0.344,\n",
       " 'abedi': 0.341,\n",
       " 'children': 0.161,\n",
       " 'feminism': 0.34,\n",
       " 'cents': 0.337,\n",
       " 'airline': 0.337,\n",
       " 'muslim': 0.324,\n",
       " 'que': 0.163,\n",
       " 'wage': 0.322,\n",
       " 'madrid': 0.14,\n",
       " 'families': 0.321,\n",
       " 'extradition': 0.321,\n",
       " 'flag': 0.314,\n",
       " 'vagina': 0.314,\n",
       " 'parent': 0.314,\n",
       " 'german': 0.314,\n",
       " 'airport': 0.312,\n",
       " 'radar': 0.311,\n",
       " 'driver': 0.31,\n",
       " 'dgt': 0.31,\n",
       " 'burial': 0.308,\n",
       " 'license': 0.307,\n",
       " 'request': 0.305,\n",
       " 'figure': 0.304,\n",
       " 'young': 0.304,\n",
       " 'lover': 0.304,\n",
       " 'choke': 0.304,\n",
       " 'muslims': 0.151,\n",
       " 'maintainers': 0.302,\n",
       " 'benicarl√≥': 0.302,\n",
       " 'drink': 0.301,\n",
       " 'actor': 0.3,\n",
       " 'immigrants': 0.298,\n",
       " 'spaniards': 0.297,\n",
       " 'vandalism': 0.296,\n",
       " 'plastic': 0.295,\n",
       " 'grain': 0.295,\n",
       " 'spanish': 0.242,\n",
       " 'six': 0.293,\n",
       " 'magi': 0.218,\n",
       " 'oxford': 0.29,\n",
       " 'voters': 0.29,\n",
       " 'devour': 0.288,\n",
       " 'card': 0.286,\n",
       " 'red': 0.286,\n",
       " 'thai': 0.286,\n",
       " 'poison': 0.285,\n",
       " 'oral': 0.285,\n",
       " 'security': 0.284,\n",
       " 'years': 0.255,\n",
       " 'scene': 0.279,\n",
       " 'de': 0.22,\n",
       " 'magazines': 0.278,\n",
       " 'obama': 0.278,\n",
       " 'diskjockey': 0.276,\n",
       " 'animal': 0.275,\n",
       " 'prosecutor': 0.275,\n",
       " 'gay': 0.274,\n",
       " 'officer': 0.169,\n",
       " 'manchester': 0.272,\n",
       " 'test': 0.153,\n",
       " 'council': 0.27,\n",
       " 'veil': 0.269,\n",
       " 'islamophobic': 0.269,\n",
       " 'study': 0.266,\n",
       " 'welcome': 0.266,\n",
       " 'aquarius': 0.266,\n",
       " 'inmates': 0.265,\n",
       " 'law': 0.265,\n",
       " 'lana': 0.264,\n",
       " 'baby': 0.264,\n",
       " 'rivera': 0.263,\n",
       " 'traffic': 0.261,\n",
       " 'pretend': 0.26,\n",
       " 'refugees': 0.26,\n",
       " 'cross': 0.26,\n",
       " 'catalan': 0.259,\n",
       " 'real': 0.259,\n",
       " 'right': 0.232,\n",
       " 'sanz': 0.257,\n",
       " 'masturbate': 0.257,\n",
       " 'die': 0.234,\n",
       " 'political': 0.254,\n",
       " 'ha': 0.253,\n",
       " 's√°nchez': 0.253,\n",
       " 'sanchez': 0.253,\n",
       " 'economy': 0.253,\n",
       " 'tons': 0.252,\n",
       " 'agents': 0.251,\n",
       " 'local': 0.131,\n",
       " 'vistalegre': 0.247,\n",
       " 'priest': 0.247,\n",
       " 'nuns': 0.247,\n",
       " 'benevolent': 0.247,\n",
       " 'rescue': 0.247,\n",
       " 'usd': 0.245,\n",
       " 'jian': 0.245,\n",
       " 'irish': 0.245,\n",
       " 'feng': 0.245,\n",
       " 'europe': 0.245,\n",
       " 'comply': 0.244,\n",
       " 'space': 0.243,\n",
       " 'volunteer': 0.243,\n",
       " 'short': 0.243,\n",
       " 'huelva': 0.243,\n",
       " 'algerian': 0.243,\n",
       " 'walk': 0.242,\n",
       " 'mother': 0.241,\n",
       " 'mayor': 0.206,\n",
       " 'song': 0.238,\n",
       " 'truth': 0.236,\n",
       " 'greet': 0.236,\n",
       " 'toxic': 0.236,\n",
       " 'practise': 0.236,\n",
       " 'rotten': 0.235,\n",
       " 'pay': 0.148,\n",
       " 'civil': 0.234,\n",
       " 'agent': 0.233,\n",
       " 'degree': 0.233,\n",
       " 'bullfighting': 0.229,\n",
       " 'university': 0.142,\n",
       " 'pilot': 0.228,\n",
       " 'companion': 0.228,\n",
       " 'tres': 0.227,\n",
       " 'cantos': 0.227,\n",
       " 'offense': 0.227,\n",
       " 'recover': 0.226,\n",
       " 'merchandise': 0.226,\n",
       " 'mountains': 0.226,\n",
       " 'guardia': 0.226,\n",
       " 'toilet': 0.225,\n",
       " 'swoop': 0.225,\n",
       " 'canadian': 0.225,\n",
       " 'minister': 0.191,\n",
       " 'pass': 0.224,\n",
       " 'wife': 0.145,\n",
       " 'city': 0.224,\n",
       " 'diputaci√≥n': 0.223,\n",
       " 'put': 0.223,\n",
       " 'sue': 0.163,\n",
       " 'trump': 0.222,\n",
       " 'hispanic': 0.222,\n",
       " 'charge': 0.221,\n",
       " 'prisons': 0.221,\n",
       " 'pedro': 0.221,\n",
       " 'steal': 0.221,\n",
       " 'en': 0.22,\n",
       " 'end': 0.22,\n",
       " 'believe': 0.219,\n",
       " 'pride': 0.219,\n",
       " 'discover': 0.219,\n",
       " 'night': 0.218,\n",
       " 'subcontract': 0.217,\n",
       " 'pucherazo': 0.217,\n",
       " 'headquarter': 0.215,\n",
       " 'vegetarian': 0.214,\n",
       " 'flesh': 0.214,\n",
       " 'swiss': 0.214,\n",
       " 'invite': 0.186,\n",
       " 'islamic': 0.151,\n",
       " 'offer': 0.21,\n",
       " 'open': 0.21,\n",
       " 'gonzalez': 0.209,\n",
       " 'child': 0.209,\n",
       " 'father': 0.14,\n",
       " 'months': 0.208,\n",
       " 'prat': 0.208,\n",
       " 'bodyguards': 0.208,\n",
       " 'iglesias': 0.208,\n",
       " 'church': 0.208,\n",
       " 'woman': 0.167,\n",
       " 'breathalyzer': 0.207,\n",
       " 'enable': 0.206,\n",
       " 'unemployed': 0.206,\n",
       " 'mili': 0.206,\n",
       " 'inem': 0.206,\n",
       " 'state': 0.187,\n",
       " 'seize': 0.205,\n",
       " 'counterfeit': 0.205,\n",
       " 'satellite': 0.205,\n",
       " 'navigation': 0.205,\n",
       " 'movie': 0.205,\n",
       " 'bmw': 0.205,\n",
       " 'management': 0.205,\n",
       " 'salamanca': 0.205,\n",
       " 'file': 0.205,\n",
       " 'apartment': 0.205,\n",
       " 'libyan': 0.204,\n",
       " 'user': 0.204,\n",
       " 'bathroom': 0.181,\n",
       " 'time': 0.204,\n",
       " 'new': 0.139,\n",
       " 'burn': 0.179,\n",
       " 'phone': 0.203,\n",
       " 'hotel': 0.203,\n",
       " 'financial': 0.202,\n",
       " 'shit': 0.202,\n",
       " 'article': 0.201,\n",
       " 'international': 0.201,\n",
       " 'facilities': 0.2,\n",
       " 'client': 0.2,\n",
       " 'white': 0.198,\n",
       " 'account': 0.198,\n",
       " 'men': 0.14,\n",
       " 'well': 0.198,\n",
       " 'association': 0.163,\n",
       " 'election': 0.197,\n",
       " 'character': 0.197,\n",
       " 'pablo': 0.195,\n",
       " 'public': 0.195,\n",
       " 'another': 0.195,\n",
       " 'nationalities': 0.195,\n",
       " 'family': 0.194,\n",
       " 'responses': 0.193,\n",
       " 'math': 0.193,\n",
       " 'la': 0.155,\n",
       " 'hortel': 0.193,\n",
       " 'shepherd': 0.192,\n",
       " 'river': 0.192,\n",
       " 'mthethwa': 0.192,\n",
       " 'jonathan': 0.192,\n",
       " 'violence': 0.191,\n",
       " 'calvo': 0.191,\n",
       " 'valenciana': 0.191,\n",
       " 'syrian': 0.191,\n",
       " 'flat': 0.191,\n",
       " 'authorization': 0.191,\n",
       " 'accessible': 0.191,\n",
       " 'albert': 0.189,\n",
       " 'people': 0.139,\n",
       " 'racial': 0.187,\n",
       " 'vehicles': 0.186,\n",
       " 'heaven': 0.186,\n",
       " 'belong': 0.186,\n",
       " 'enjoy': 0.186,\n",
       " 'his': 0.185,\n",
       " 'collection': 0.185,\n",
       " 'kingdom': 0.185,\n",
       " 'support': 0.154,\n",
       " 'point': 0.185,\n",
       " 'tradition': 0.185,\n",
       " 'president': 0.146,\n",
       " 'demonstration': 0.183,\n",
       " 'third': 0.183,\n",
       " 'must': 0.169,\n",
       " 'work': 0.181,\n",
       " 'celebrate': 0.181,\n",
       " 'strasbourg': 0.18,\n",
       " 'processions': 0.18,\n",
       " 'iranian': 0.18,\n",
       " 'easter': 0.18,\n",
       " 'man': 0.147,\n",
       " 'say': 0.179,\n",
       " 'uned': 0.179,\n",
       " 'mouthpieces': 0.179,\n",
       " 'mouthpiece': 0.179,\n",
       " 'breathalyzers': 0.179,\n",
       " 'colau': 0.177,\n",
       " 'ada': 0.177,\n",
       " 'sex': 0.176,\n",
       " 'we': 0.176,\n",
       " 'strong': 0.176,\n",
       " 'abort': 0.176,\n",
       " 'legal': 0.175,\n",
       " 'review': 0.175,\n",
       " 'handle': 0.175,\n",
       " 'you': 0.175,\n",
       " 'shakira': 0.175,\n",
       " 'navarra': 0.175,\n",
       " 'mart√≠n': 0.175,\n",
       " 'madman': 0.175,\n",
       " 'machists': 0.175,\n",
       " 'machismo': 0.175,\n",
       " 'dani': 0.175,\n",
       " 'amaral': 0.175,\n",
       " 'cause': 0.144,\n",
       " 'followers': 0.174,\n",
       " 'sexist': 0.154,\n",
       " 'carmen': 0.173,\n",
       " 'queen': 0.173,\n",
       " 'parade': 0.173,\n",
       " 'chariot': 0.173,\n",
       " 'disable': 0.173,\n",
       " 'merkel': 0.173,\n",
       " 'debate': 0.173,\n",
       " 'secretary': 0.172,\n",
       " 'municipal': 0.172,\n",
       " 'district': 0.172,\n",
       " 'condition': 0.172,\n",
       " 'air': 0.172,\n",
       " 'united': 0.172,\n",
       " 'british': 0.172,\n",
       " 'express': 0.172,\n",
       " 'change': 0.131,\n",
       " 'statue': 0.171,\n",
       " 'jorge': 0.171,\n",
       " 'hospitalet': 0.17,\n",
       " 'feces': 0.17,\n",
       " 'el': 0.17,\n",
       " 'animals': 0.17,\n",
       " 'playing': 0.17,\n",
       " 'body': 0.17,\n",
       " 'human': 0.169,\n",
       " 'smell': 0.168,\n",
       " 'attack': 0.136,\n",
       " 'plug': 0.168,\n",
       " 'placement': 0.168,\n",
       " 'bego√±a': 0.168,\n",
       " 'badajoz': 0.168,\n",
       " 'think': 0.167,\n",
       " 'world': 0.167,\n",
       " 'republican': 0.167,\n",
       " 'prison': 0.135,\n",
       " 'del': 0.165,\n",
       " 'wear': 0.164,\n",
       " 'fascist': 0.164,\n",
       " 'population': 0.164,\n",
       " 'times': 0.163,\n",
       " 'list': 0.159,\n",
       " 'religion': 0.163,\n",
       " 'faith': 0.163,\n",
       " 'teachers': 0.163,\n",
       " 'computer': 0.163,\n",
       " 'close': 0.162,\n",
       " 'important': 0.162,\n",
       " 'amount': 0.134,\n",
       " 'organization': 0.162,\n",
       " 'montes': 0.161,\n",
       " 'temporary': 0.161,\n",
       " 'permit': 0.161,\n",
       " 'deputy': 0.161,\n",
       " 'spf': 0.161,\n",
       " 'prisoner': 0.161,\n",
       " 'famous': 0.161,\n",
       " 'generalitat': 0.161,\n",
       " 'start': 0.16,\n",
       " 'gabriel': 0.16,\n",
       " 'eventual': 0.16,\n",
       " 'anna': 0.16,\n",
       " 'serve': 0.16,\n",
       " 'husband': 0.16,\n",
       " 'topics': 0.151,\n",
       " 'program': 0.159,\n",
       " 'house': 0.159,\n",
       " 'research': 0.158,\n",
       " 'need': 0.158,\n",
       " 'malaga': 0.158,\n",
       " 'friend': 0.158,\n",
       " 'drag': 0.157,\n",
       " 'cavalcade': 0.157,\n",
       " 'carmena': 0.157,\n",
       " 'unusual': 0.157,\n",
       " 'sustacia': 0.157,\n",
       " 'suspicion': 0.157,\n",
       " 'negro': 0.157,\n",
       " 'model': 0.157,\n",
       " 'view': 0.157,\n",
       " 'racist': 0.157,\n",
       " 'custody': 0.157,\n",
       " 'popular': 0.157,\n",
       " 'liturgies': 0.157,\n",
       " 'random': 0.156,\n",
       " 'explosives': 0.156,\n",
       " 'good': 0.156,\n",
       " 'announce': 0.155,\n",
       " 'neighbor': 0.155,\n",
       " 'garcia': 0.155,\n",
       " 'reject': 0.154,\n",
       " 'approve': 0.143,\n",
       " 'abuse': 0.154,\n",
       " 'find': 0.15,\n",
       " 'christians': 0.154,\n",
       " 'image': 0.154,\n",
       " 'car': 0.154,\n",
       " 'observatory': 0.153,\n",
       " 'mockery': 0.153,\n",
       " 'bully': 0.153,\n",
       " 'stress': 0.153,\n",
       " 'minutes': 0.153,\n",
       " 'gender': 0.153,\n",
       " 'g√≥mez': 0.152,\n",
       " 'david': 0.152,\n",
       " 'agency': 0.152,\n",
       " 'death': 0.152,\n",
       " 'issue': 0.151,\n",
       " 'describe': 0.151,\n",
       " 'storm': 0.151,\n",
       " 'premise': 0.151,\n",
       " 'confiscate': 0.151,\n",
       " 'chaos': 0.151,\n",
       " 'september': 0.15,\n",
       " 'rate': 0.15,\n",
       " 'government': 0.135,\n",
       " 'measure': 0.135,\n",
       " 'social': 0.148,\n",
       " 'launch': 0.148,\n",
       " 'hate': 0.148,\n",
       " 'promote': 0.147,\n",
       " 'high': 0.147,\n",
       " 'former': 0.147,\n",
       " 'party': 0.147,\n",
       " 'able': 0.147,\n",
       " 'interior': 0.146,\n",
       " 'foreigners': 0.146,\n",
       " 'two': 0.146,\n",
       " 'take': 0.134,\n",
       " 'successful': 0.145,\n",
       " 'orientation': 0.145,\n",
       " 'galician': 0.145,\n",
       " 'clauses': 0.145,\n",
       " 'insolidarity': 0.145,\n",
       " 'prasit': 0.143,\n",
       " 'meat': 0.143,\n",
       " 'bangkok': 0.143,\n",
       " 'power': 0.143,\n",
       " 'impregnate': 0.142,\n",
       " 'assassination': 0.142,\n",
       " 'respect': 0.142,\n",
       " 'hand': 0.142,\n",
       " 'throughout': 0.142,\n",
       " 'islam': 0.142,\n",
       " 'torra': 0.141,\n",
       " 'race': 0.141,\n",
       " 'catalans': 0.141,\n",
       " 'link': 0.14,\n",
       " 'would': 0.134,\n",
       " 'commit': 0.14,\n",
       " 'generate': 0.14,\n",
       " 'king': 0.14,\n",
       " 'fully': 0.14,\n",
       " 'bring': 0.139,\n",
       " 'polo': 0.139,\n",
       " 'declarant': 0.139,\n",
       " 'bar': 0.139,\n",
       " 'almer√≠a': 0.139,\n",
       " 'inclusive': 0.139,\n",
       " 'celebration': 0.139,\n",
       " 'slowly': 0.138,\n",
       " 'slow': 0.138,\n",
       " 'punch': 0.138,\n",
       " 'pounce': 0.138,\n",
       " 'nightclub': 0.138,\n",
       " 'logro√±o': 0.138,\n",
       " 'heavy': 0.138,\n",
       " 'grandstand': 0.138,\n",
       " 'fonsi': 0.138,\n",
       " 'exalted': 0.138,\n",
       " 'endure': 0.138,\n",
       " 'dj': 0.138,\n",
       " 'disco': 0.138,\n",
       " 'defiant': 0.138,\n",
       " 'climb': 0.138,\n",
       " 'basto': 0.138,\n",
       " 'case': 0.138,\n",
       " 'try': 0.138,\n",
       " 'rebuke': 0.137,\n",
       " 'special': 0.136,\n",
       " 'guard': 0.136,\n",
       " 'bomb': 0.136,\n",
       " 'require': 0.136,\n",
       " 'hunt': 0.136,\n",
       " 'assistance': 0.135,\n",
       " 'every': 0.135,\n",
       " 'leave': 0.131,\n",
       " 'citizens': 0.135,\n",
       " 'create': 0.134,\n",
       " 'true': 0.134,\n",
       " 'presence': 0.134,\n",
       " 'statistics': 0.133,\n",
       " 'compare': 0.133,\n",
       " 'controversial': 0.132,\n",
       " 'brother': 0.132,\n",
       " 'victim': 0.132,\n",
       " 'attempt': 0.132,\n",
       " 'health': 0.132,\n",
       " 'framework': 0.132,\n",
       " 'discrimination': 0.132,\n",
       " 'direct': 0.132,\n",
       " 'progressive': 0.131,\n",
       " 'frighten': 0.131,\n",
       " 'cut': 0.131,\n",
       " 'coordinator': 0.131,\n",
       " 'trade': 0.131,\n",
       " 'alternative': 0.131,\n",
       " 'school': 0.131}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Real news relevant words\n",
    "It needs to do the same process but with real news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_words_real_train = tfidf_model_real.transform(cv_train_real)\n",
    "results_real, top_real_words = tf.get_topn_relevant_words(cv, tf_words_real_train, topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bitcoin',\n",
       " 'mw',\n",
       " 'columbus',\n",
       " 'attack',\n",
       " 'purchase',\n",
       " 'bbva',\n",
       " 'maroto',\n",
       " 'vox',\n",
       " 'education',\n",
       " 'bettong',\n",
       " 'degree',\n",
       " 'valeria',\n",
       " 'frb',\n",
       " 'burst',\n",
       " 'passengers',\n",
       " 'bbva',\n",
       " 'calvi√±o',\n",
       " 'manicure',\n",
       " 'listen',\n",
       " 'operations',\n",
       " 'sesame',\n",
       " 'netflix',\n",
       " 'price',\n",
       " 'catalonia',\n",
       " 'borrell',\n",
       " 'waistcoats',\n",
       " 'liceu',\n",
       " 'conservatory',\n",
       " 'statue',\n",
       " 'bet',\n",
       " 'liter',\n",
       " 'abascal',\n",
       " 'choke',\n",
       " 'congress',\n",
       " 'death',\n",
       " 'survivors',\n",
       " 'political',\n",
       " 'motion',\n",
       " 'washington',\n",
       " 'panda',\n",
       " 'giant',\n",
       " 'syria',\n",
       " 'ambulances',\n",
       " 'cuba',\n",
       " 'movistar',\n",
       " 'workers',\n",
       " 'yellow',\n",
       " 'authority',\n",
       " 'january',\n",
       " 'unemployment',\n",
       " 'artists',\n",
       " 'disinformation',\n",
       " 'hathaway',\n",
       " 'moreno',\n",
       " 'xiaomi',\n",
       " 'ikea',\n",
       " 'introduce',\n",
       " 'plaque',\n",
       " 'quer',\n",
       " 'wilson',\n",
       " 'abuse',\n",
       " 'sport',\n",
       " 'coward',\n",
       " 'payton',\n",
       " 'fox',\n",
       " 'refugees',\n",
       " 'foreigners',\n",
       " 'ryanair',\n",
       " 'aviation',\n",
       " 'radio',\n",
       " 'fine',\n",
       " 'private',\n",
       " 'patrol',\n",
       " 'gibraltar',\n",
       " 'wind',\n",
       " 'offshore',\n",
       " 'zarzuela',\n",
       " 'employment',\n",
       " 'euros',\n",
       " 'elections',\n",
       " 'hanukkah',\n",
       " 'law',\n",
       " 'health',\n",
       " 'ot',\n",
       " 'pp',\n",
       " 'crime',\n",
       " 'film',\n",
       " 'chinese',\n",
       " 'petrol',\n",
       " 'diesel',\n",
       " 'european',\n",
       " 'center',\n",
       " 'detect',\n",
       " 'city',\n",
       " 'brexit',\n",
       " 'italian',\n",
       " 'habitat',\n",
       " 'psoe',\n",
       " 'purchase',\n",
       " 'korea',\n",
       " 'japanese',\n",
       " 'japan',\n",
       " 'dissolve',\n",
       " 'stab',\n",
       " 'paris',\n",
       " 'project',\n",
       " 'online',\n",
       " 'water',\n",
       " 'roger',\n",
       " 'fund',\n",
       " 'home',\n",
       " 'technical',\n",
       " 'advantage',\n",
       " 'products',\n",
       " 'statute',\n",
       " 'game',\n",
       " 'telef√≥nica',\n",
       " 'cs',\n",
       " 'sabela',\n",
       " 'red',\n",
       " 'script',\n",
       " 'googletag',\n",
       " 'store',\n",
       " 'pdecat',\n",
       " 'congress',\n",
       " 'urkullu',\n",
       " 'sant',\n",
       " 'joan',\n",
       " 'desp√≠',\n",
       " 'basque',\n",
       " 'personal',\n",
       " 'enjoy',\n",
       " 'data',\n",
       " 'carlos',\n",
       " 'south',\n",
       " 'fuel',\n",
       " 'price',\n",
       " 'parliament',\n",
       " 'agreement',\n",
       " 'civil',\n",
       " 'communities',\n",
       " 'yolanda',\n",
       " 'cover',\n",
       " 'infanta',\n",
       " 'elena',\n",
       " 'cross',\n",
       " 'week',\n",
       " 'news',\n",
       " 'buy',\n",
       " 'european',\n",
       " 'oil',\n",
       " 'actress',\n",
       " 'monarch',\n",
       " 'emeritus',\n",
       " 'football',\n",
       " 'brand',\n",
       " 'villarejo',\n",
       " 'supreme',\n",
       " 'may',\n",
       " 'spokespersons',\n",
       " 'bosquet',\n",
       " 'time',\n",
       " 'president',\n",
       " 'object',\n",
       " 'church',\n",
       " 'king',\n",
       " 'morning',\n",
       " 'retain',\n",
       " 'mot√≥nity',\n",
       " 'motorcycle',\n",
       " 'electoral',\n",
       " 'jury',\n",
       " 'gala',\n",
       " 'zoo',\n",
       " 'storm',\n",
       " 'snow',\n",
       " 'bei',\n",
       " 'post',\n",
       " 'malone',\n",
       " 'police',\n",
       " 'neighbor',\n",
       " 'countries',\n",
       " 'merger',\n",
       " 'fusion',\n",
       " 'products',\n",
       " 'black',\n",
       " 'network',\n",
       " 'usd',\n",
       " 'economy',\n",
       " 'finance',\n",
       " 'cause',\n",
       " 'wikinger',\n",
       " 'students',\n",
       " 'barcelona',\n",
       " 'rebound',\n",
       " 'dollars',\n",
       " 'russia',\n",
       " 'mossos',\n",
       " 'marta',\n",
       " 'juanma',\n",
       " 'firm',\n",
       " 'smart',\n",
       " 'bulbs',\n",
       " 'alliance',\n",
       " 'develop',\n",
       " 'catholic',\n",
       " 'australian',\n",
       " 'vietnamese',\n",
       " 'exploit',\n",
       " 'investments',\n",
       " 'juan',\n",
       " 'patrimonial',\n",
       " 'price',\n",
       " 'genocide',\n",
       " 'various',\n",
       " 'mother',\n",
       " 'knife',\n",
       " 'banyoles',\n",
       " 'space',\n",
       " 'day',\n",
       " 'valenciana',\n",
       " 'disable',\n",
       " 'accessible',\n",
       " 'spanish',\n",
       " 'final',\n",
       " 'agreement',\n",
       " 'nationality',\n",
       " 'brussels',\n",
       " 'insider',\n",
       " 'abengoa',\n",
       " 'cenyt',\n",
       " 'series',\n",
       " 'commission',\n",
       " 'staff',\n",
       " 'eu',\n",
       " 'digital',\n",
       " 'article',\n",
       " 'company',\n",
       " 'casinos',\n",
       " 'complaint',\n",
       " 'germany',\n",
       " 'decision',\n",
       " 'countries',\n",
       " 'holocaust',\n",
       " 'charlotte',\n",
       " 'food',\n",
       " 'cela√°',\n",
       " 'natalia',\n",
       " 'state',\n",
       " 'act',\n",
       " 'bank',\n",
       " 'wave',\n",
       " 'signal',\n",
       " 'chime',\n",
       " 'substantial',\n",
       " 'marginal',\n",
       " 'italy',\n",
       " 'ozuna',\n",
       " 'lipa',\n",
       " 'dua',\n",
       " 'drake',\n",
       " 'bunny',\n",
       " 'balvin',\n",
       " 'bad',\n",
       " 'fake',\n",
       " 'university',\n",
       " 'update',\n",
       " 'many',\n",
       " 'zone',\n",
       " 'timetable',\n",
       " 'schedule',\n",
       " 'geographical',\n",
       " 'ceoe',\n",
       " 'illegally',\n",
       " 'undertake',\n",
       " 'provision',\n",
       " 'argument',\n",
       " 'top',\n",
       " 'television',\n",
       " 'security',\n",
       " 'man',\n",
       " 'car',\n",
       " 'cnmv',\n",
       " 'would',\n",
       " 'kill',\n",
       " 'gonzalez',\n",
       " 'floor',\n",
       " 'diana',\n",
       " 'minor',\n",
       " 'tories',\n",
       " 'theresa',\n",
       " 'telegraph',\n",
       " 'parliamentarians',\n",
       " 'commons',\n",
       " 'family',\n",
       " 'generalitat',\n",
       " 'flat',\n",
       " 'authorization',\n",
       " 'right',\n",
       " 'party',\n",
       " 'engineer',\n",
       " 'architect',\n",
       " 'residents',\n",
       " 'buy',\n",
       " 'unacceptable',\n",
       " 'korean',\n",
       " 'comfort',\n",
       " 'abe',\n",
       " 'tax',\n",
       " 'strike',\n",
       " 'flight',\n",
       " 'compensation',\n",
       " 'caa',\n",
       " 'aviationadr',\n",
       " 'date',\n",
       " 'candidate',\n",
       " 'world',\n",
       " 'minister',\n",
       " 'valls',\n",
       " 'eye',\n",
       " 'boycott',\n",
       " 'vote',\n",
       " 'villarejo',\n",
       " 'irregularities',\n",
       " 'internal',\n",
       " 'documentation',\n",
       " 'smi',\n",
       " 'imf',\n",
       " 'crisis',\n",
       " 'raid',\n",
       " 'navy',\n",
       " 'incident',\n",
       " 'defense',\n",
       " 'commander',\n",
       " 'senator',\n",
       " 'investigation',\n",
       " 'british',\n",
       " 'party',\n",
       " 'must',\n",
       " 'network',\n",
       " 'catalan',\n",
       " 'seat',\n",
       " 'cs',\n",
       " 'campaign',\n",
       " 'brussels',\n",
       " 'statute',\n",
       " 'british',\n",
       " 'famous',\n",
       " 'party',\n",
       " 's√°nchez',\n",
       " 'pdecat',\n",
       " 'gdp',\n",
       " 'fulfil',\n",
       " 'erc',\n",
       " 'swallow',\n",
       " 'victim',\n",
       " 'kill',\n",
       " 'admit',\n",
       " 'baltic',\n",
       " 'death',\n",
       " 'syrian',\n",
       " 'vox',\n",
       " 'friday',\n",
       " 'stop',\n",
       " 'practice',\n",
       " 'spanish',\n",
       " 'initiative',\n",
       " 'sexual',\n",
       " 'investigation',\n",
       " 'court',\n",
       " 'total',\n",
       " 'who',\n",
       " 'mark',\n",
       " 'average',\n",
       " 'restrict',\n",
       " 'palates',\n",
       " 'employ',\n",
       " 'andalusia',\n",
       " 'wild',\n",
       " 'northern',\n",
       " 'marsupial',\n",
       " 'ecosystem',\n",
       " 'scale',\n",
       " 'economic',\n",
       " 'constitutional',\n",
       " 'france',\n",
       " 'capacity',\n",
       " 'reach',\n",
       " 'range',\n",
       " 'student',\n",
       " 'deficit',\n",
       " 'ship',\n",
       " 'organization',\n",
       " 'appeal',\n",
       " 'pedro',\n",
       " 'comply',\n",
       " 'plan',\n",
       " 'responsibility',\n",
       " 'youth',\n",
       " 'technicians',\n",
       " 'text',\n",
       " 'gonz√°lez',\n",
       " 'rivera',\n",
       " 'reche',\n",
       " 'edition',\n",
       " 'contest',\n",
       " 'alba',\n",
       " 'government',\n",
       " 'year',\n",
       " 'xxxtentacion',\n",
       " 'album',\n",
       " 'euros',\n",
       " 'young',\n",
       " 'sale',\n",
       " 'fail',\n",
       " 'week',\n",
       " 'discount',\n",
       " 'in',\n",
       " 'warner',\n",
       " 'stranger',\n",
       " 'movie',\n",
       " 'bros',\n",
       " 'woman',\n",
       " 'win',\n",
       " 'vox',\n",
       " 'budget',\n",
       " 'law',\n",
       " 'european',\n",
       " 'plan',\n",
       " 'propose',\n",
       " 'deaths',\n",
       " 'report',\n",
       " 'prepare',\n",
       " 'emergency',\n",
       " 'design',\n",
       " 'conservative',\n",
       " 'sign',\n",
       " 'application',\n",
       " 'point',\n",
       " 'derive',\n",
       " 'removal',\n",
       " 'envisage',\n",
       " 'wet',\n",
       " 'paper',\n",
       " 'philip',\n",
       " 'paedophilia',\n",
       " 'convict',\n",
       " 'archbishop',\n",
       " 'adelaide',\n",
       " 'accept',\n",
       " 'plan',\n",
       " 'puigdemont',\n",
       " 'women',\n",
       " 'relations',\n",
       " 'mccain',\n",
       " 'magazine',\n",
       " 'flu',\n",
       " 'editor',\n",
       " 'commotion',\n",
       " 'california',\n",
       " 'bre',\n",
       " 'bray',\n",
       " 'home',\n",
       " 'american',\n",
       " 'dominate',\n",
       " 'measure',\n",
       " 'framework',\n",
       " 'commitment',\n",
       " 'head',\n",
       " 'cs',\n",
       " 'charge',\n",
       " 'people',\n",
       " 'wunderlich',\n",
       " 'terrain',\n",
       " 'easy',\n",
       " 'andalusia',\n",
       " 'miguel',\n",
       " 'warn',\n",
       " 'australia',\n",
       " 'increase',\n",
       " 'socialist',\n",
       " 'profile',\n",
       " 'agreement',\n",
       " 'government',\n",
       " 'murder',\n",
       " 'people',\n",
       " 'court',\n",
       " 'june',\n",
       " 'protection',\n",
       " 'leisure',\n",
       " 'first',\n",
       " 'agenda',\n",
       " 'urjc',\n",
       " 'qualification',\n",
       " 'criminology',\n",
       " 'appellant',\n",
       " 'socialist',\n",
       " 'case',\n",
       " 'similar',\n",
       " 'labour',\n",
       " 'public',\n",
       " 'change',\n",
       " 'figure',\n",
       " 'survive',\n",
       " 'knobloch',\n",
       " 'jews',\n",
       " 'jewish',\n",
       " 'father',\n",
       " 'breathe',\n",
       " 'pp',\n",
       " 'require',\n",
       " 'newspaper',\n",
       " 'suffer',\n",
       " 'force',\n",
       " 'aid',\n",
       " 'locate',\n",
       " 'scientists',\n",
       " 'mysterious',\n",
       " 'government',\n",
       " 'unit',\n",
       " 'monthly',\n",
       " 'affect',\n",
       " 'platforms',\n",
       " 'check',\n",
       " 'document',\n",
       " 'producer',\n",
       " 'inspire',\n",
       " 'form',\n",
       " 'famous',\n",
       " 'anne',\n",
       " 'lose',\n",
       " 'wednesday',\n",
       " 'measure',\n",
       " 'reform',\n",
       " 'rome',\n",
       " 'latvian',\n",
       " 'dombrovskis',\n",
       " 'operation',\n",
       " 'direct',\n",
       " 'whether',\n",
       " 'issue',\n",
       " 'discovery',\n",
       " 'educational',\n",
       " 'councillor',\n",
       " 'chair',\n",
       " 'united',\n",
       " 'great',\n",
       " 'square',\n",
       " 'north',\n",
       " 'government',\n",
       " 'abascal',\n",
       " 'sentence',\n",
       " 'prison',\n",
       " 'judge',\n",
       " 'impose',\n",
       " 'illegally',\n",
       " 'impressive',\n",
       " 'criptomonedas',\n",
       " 'union',\n",
       " 'opposition',\n",
       " 'members',\n",
       " 'parliamentary',\n",
       " 'approve',\n",
       " 'return',\n",
       " 'scene',\n",
       " 'kitchen',\n",
       " 'eldest',\n",
       " 'palmas',\n",
       " 'las',\n",
       " 'half',\n",
       " 'offer',\n",
       " 'end',\n",
       " 'new',\n",
       " 'spokesman',\n",
       " 'british',\n",
       " 'ideological',\n",
       " 'activities',\n",
       " 'numerous',\n",
       " 'moroccan',\n",
       " 'castile',\n",
       " 'maintain',\n",
       " 'growth',\n",
       " 'front',\n",
       " 'right',\n",
       " 'options',\n",
       " 'client',\n",
       " 'day',\n",
       " 'lament',\n",
       " 'first',\n",
       " 'luis',\n",
       " 'parliament',\n",
       " 'regional',\n",
       " 'campaign',\n",
       " 'judgement',\n",
       " 'online',\n",
       " 'reality',\n",
       " 'negotiate',\n",
       " 'number',\n",
       " 'fact',\n",
       " 'open']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_real_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Create Doc2Vec model and compute similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from scipy import spatial\n",
    "\n",
    "def tag_docs(docs, col):\n",
    "    tagged = docs.apply(lambda r: TaggedDocument(words=r[col], tags=[r.label]), axis=1)\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = tag_docs(dataset, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(total_docs, dm = 0, min_count=3, window=10, size=50, sample=1e-4, negative=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_real = model.infer_vector(top_real_words)\n",
    "vec_fake = model.infer_vector(top_fake_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Calculate similarity between documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tagged, df_test_tagged = train_test_split(total_docs, test_size=0.2, random_state=42) # Using the same seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, train_tagged = get_vectors(model, df_train_tagged)\n",
    "Y_test, test_tagged = get_vectors(model, df_test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_similarity = []\n",
    "for element in train_tagged:\n",
    "    similairty_real = spatial.distance.cosine(element, vec_real)\n",
    "    similairty_fake = spatial.distance.cosine(element, vec_fake)\n",
    "    train_similarity.append([similairty_real,similairty_fake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_similarity = []\n",
    "for element in test_tagged:\n",
    "    similairty_real = spatial.distance.cosine(element, vec_real)\n",
    "    similairty_fake = spatial.distance.cosine(element, vec_fake)\n",
    "    test_similarity.append([similairty_real,similairty_fake])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Create Doc2Vec model and compute similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fake_news_detector.core.classificators import SupportVectorMachine as svm_controller\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_similarity\n",
    "X_test = test_similarity\n",
    "rbf_values = svm_controller.svc_param_selection(X_train, Y_train, 2, 'rbf')\n",
    "linear_values = svm_controller.svc_param_selection(X_train, Y_train, 2, 'linear')\n",
    "poly_values = svm_controller.svc_param_selection(X_train, Y_train, 2, 'poly')\n",
    "sigmoid_values = svm_controller.svc_param_selection(X_train, Y_train, 2, 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['rbf'] = svm.SVC(kernel='rbf', C= rbf_values['C'], gamma=rbf_values['gamma'])\n",
    "models['linear']  = svm.SVC(kernel='linear', C= linear_values['C'], gamma=linear_values['gamma'])\n",
    "models['poly']  = svm.SVC(kernel='poly',C=poly_values['C'], gamma=poly_values['gamma'])\n",
    "models['sigmoid'] = svm.SVC(kernel='sigmoid', C=sigmoid_values['C'], gamma=sigmoid_values['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model rbf\n",
      "Training score: 0.5229357798165137. Test score: 0.4642857142857143\n",
      "For model linear\n",
      "Training score: 0.5229357798165137. Test score: 0.4642857142857143\n",
      "For model poly\n",
      "Training score: 0.5229357798165137. Test score: 0.4642857142857143\n",
      "For model sigmoid\n",
      "Training score: 0.5229357798165137. Test score: 0.4642857142857143\n"
     ]
    }
   ],
   "source": [
    "scores = svm_controller.run_models(models, X_train, Y_train, X_test, Y_test)\n",
    "for model in scores:\n",
    "    print('For model', model)\n",
    "    print('Training score: {}. Test score: {}'.format(scores[model]['train'],scores[model]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0438207276165485, 0.7886397689580917],\n",
       " [1.0439171642065048, 0.79187972843647],\n",
       " [1.0436461009085178, 0.7890965044498444],\n",
       " [1.0415050648152828, 0.7904908806085587],\n",
       " [1.0426413342356682, 0.7959313094615936],\n",
       " [1.0471894592046738, 0.7938645333051682],\n",
       " [1.0498887673020363, 0.790956661105156],\n",
       " [1.0422907620668411, 0.7843248248100281],\n",
       " [1.0486450716853142, 0.7905933409929276],\n",
       " [1.0463269129395485, 0.787962332367897]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
