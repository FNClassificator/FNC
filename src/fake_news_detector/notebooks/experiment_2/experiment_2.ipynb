{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: BOW/TFIDF + LDA + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for Jupyter Notebook\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.utils import io\n",
    "\n",
    "from src.fake_news_detector.core.encoders import bow as b\n",
    "from src.fake_news_detector.core.encoders import tfidf as t\n",
    "from src.fake_news_detector.core.classificators import latent_analysis as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import `dataset_raw.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/dataset_raw.json')\n",
    "df = pd.DataFrame(data=articles['articles']) # Put in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get useful info from our dataset:\n",
    "corpus = pd.DataFrame()\n",
    "corpus['corpus'] = df['all_word']\n",
    "corpus['label'] = df['fake']*1\n",
    "len(df)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dictionary creation and word vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = True\n",
    "filter_by_freq = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 BOW encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(corpus['corpus'])\n",
    "filter_by_freq = True\n",
    "ouput = True\n",
    "\n",
    "corpus['bow_encoding'], dictionary = b.bow_encoding(list(df['all_word']),True, True, 0.6, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_encoding, tfidf_dictionary = b.run_tfidf(df['corpus'], filter_by_freq, output)\n",
    "df['tfidf_encoding'] = t.tfidf_encoding(list(corpus['bow_encoding']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Topic modeling with LDA\n",
    "\n",
    "Separate train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_content, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train['id'] = list(range(0,len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for showing top topics of fake and real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_top_topics_by_label(lda_model, corpus, labels):\n",
    "    for label in labels:\n",
    "        sub_corpus = corpus.loc[corpus['label'] == label]\n",
    "        topic_distribution = sub_corpus['lda_featrues'].mean()\n",
    "        \n",
    "        x = range(0, len(topic_distribution))\n",
    "        plt.bar(x, topic_distribution, color=\"blue\")\n",
    "        \n",
    "        print(\"Looking up top words from top topics from\", label)\n",
    "        for x in sorted(np.argsort(topic_distribution)[-5:]):\n",
    "            top_words = lda.get_top_words_by_id(lda_model, x)\n",
    "            print(\"For topic {}, the top words are: {}.\".format(x, \", \".join(top_words)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 BOW\n",
    "\n",
    "Create LDA model with BOW encoding and show top words of each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_lda_model = la.create_LDA(df_train['bow_encoding'], dictionary)\n",
    "lda.print_top_words(bow_lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store topic distribution of each document in dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bow_lda_featrues'] = ld.get_topics_distribution_by_doc(bow_lda_model, dictionary, list(df_train['corpus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show top topics with its words of real and fake news. (From train dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1]\n",
    "print_top_topics_by_label(bow_lda_model, list(df_train['corpus']), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['bow_lda_features'] = la.get_all_topic_predictions(lda_model, df_test['corpus'])\n",
    "print_top_topics_by_label(bow_lda_model, list(df_train['corpus']), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "ld.model_evaluation(bow_lda_model, list(df_test['corpus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Check a random document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lsi_model = la.create_LSI(df_train['tfidf_encoding'], dictionary)\n",
    "lda.print_top_words(tfidf_lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tfidf_lda_featrues'] = lda.get_topics_distribution_by_doc(tfidf_lda_model, dictionary, list(df_train['corpus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1]\n",
    "print_top_topics_by_label(tfidf_lda_model, list(df_train['corpus']), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['tfidf_lda_features'] = lda.get_all_topic_predictions(lda_model, df_test['corpus'])\n",
    "print_top_topics_by_label(tfidf_lda_model, list(df_train['corpus']), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "ld.model_evaluation(tfidf_lsi_model, list(df_test['corpus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction with LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fake_news_detector.core.classificator import lr, helpers\n",
    "\n",
    "y_train = np.array(list(df_train.label))\n",
    "y_test = np.array(list(df_test.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train and set data input\n",
    "X_train = np.array(list(map(np.array, df_train.bow_lda_features)))\n",
    "X_test = np.array(list(map(np.array, df_test.bow_lda_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with LR\n",
    "lr_model = lr.create_model()\n",
    "lr.train_model(lr_model, X_train, y_train)\n",
    "y_pred = lr.predict(lr_model, X_test)\n",
    "\n",
    "helpers.print_evaluation(lr_model, X_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train and set data input\n",
    "X_train = np.array(list(map(np.array, df_train.tfidf_lda_features)))\n",
    "X_test = np.array(list(map(np.array, df_test.tfidf_lda_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with LR\n",
    "lr_model = lr.create_model()\n",
    "lr.train_model(lr_model, X_train, y_train)\n",
    "y_pred = lr.predict(lr_model, X_test)\n",
    "\n",
    "helpers.print_evaluation(lr_model, X_train, y_train, y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
