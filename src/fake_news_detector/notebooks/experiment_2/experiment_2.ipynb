{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: BOW/TFIDF + LDA + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for Jupyter Notebook\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.utils import io\n",
    "\n",
    "from src.fake_news_detector.core.encoders import bow as b\n",
    "from src.fake_news_detector.core.encoders import tfidf as t\n",
    "#LDA\n",
    "from src.fake_news_detector.core.classificators import LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `raw_dataset.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/raw_content.json')\n",
    "df = pd.DataFrame(data=articles['articles']) # Put in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content = pd.DataFrame()\n",
    "df_content['corpus'] = df['all_word']\n",
    "df_content['label'] = df['fake']*1\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary creation and word vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = True\n",
    "filter_by_freq = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BOW encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_encoding, bow_dictionary = b.run_BOW(df['corpus'], filter_by_freq, output)\n",
    "df['bow_encoding'] = bow_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_encoding, tfidf_dictionary = b.run_tfidf(df['corpus'], filter_by_freq, output)\n",
    "#df['tfidf_encoding'] = tfidf_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT in datasets\n",
    "# df_train, df_test =\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_top_topics_by_label(lda_model, corpus, labels):\n",
    "    for label in labels:\n",
    "        sub_corpus = corpus.loc[corpus['label'] == label]\n",
    "        topic_distribution = sub_corpus['lda_featrues'].mean()\n",
    "        \n",
    "        x = range(0, len(topic_distribution))\n",
    "        plt.bar(x, topic_distribution, color=\"blue\")\n",
    "        \n",
    "        print(\"Looking up top words from top topics from\", label)\n",
    "            for x in sorted(np.argsort(topic_distribution)[-5:]):\n",
    "                top_words = lda.get_top_words_by_id(lda_model, x)\n",
    "                print(\"For topic {}, the top words are: {}.\".format(x, \", \".join(top_words)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_lda = lda.create_LDA(df_train['bow_encoding'], bow_dictionary)\n",
    "#Get top topics per label\n",
    "labels = [0, 1]\n",
    "\n",
    "df_train['lda_featrues'] = lda.get_all_topic_predictions(lda_model, df_train['corpus'])\n",
    "print_top_topics_by_label(bow_lda, df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(corpus, x_test, y_test, dictionary):\n",
    "    lda_model = lda.create_LDA(corpus, dictionary)\n",
    "    y_pred = lda.get_all_topic_predictions(lda_model, x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(list(map(np.array, df_train.lda_features)))\n",
    "y_train = np.array(list(df_train.label))\n",
    "\n",
    "df_test['lda_features'] = lda.get_all_topic_predictions(lda_model, df_test['corpus'])\n",
    "X_test = np.array(list(map(np.array, df_test.lda_features)))\n",
    "y_test = np.array(list(df_test.label))\n",
    "\n",
    "# 1. Create model\n",
    "svc_model = svc.SVC_default()\n",
    "# 2. Process SVC\n",
    "svc.run_results(svc_model, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
