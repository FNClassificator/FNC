{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.utils import io\n",
    "\n",
    "from src.fake_news_detector.core.encoders import tfidf as tf \n",
    "from src.fake_news_detector.core.classificators import SupportVectorMachine as svm_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import `dataset_content.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/dataset_content.json')\n",
    "df = pd.DataFrame(data=articles['articles']) # Put in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_lists(dataset, word_lists):\n",
    "    result = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        text_join = \"\"\n",
    "        for feature in word_lists:\n",
    "            doc_list = row[feature]\n",
    "            text_join += ' '.join(doc_list)\n",
    "        result.append(text_join)\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>find corpse vegetarian restaurant Bangkok find...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>switzerland warn authorize extradition politic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>navarre censor Songs Amaral Shakira song Madma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>woman pretend blind years greet people Now tru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrested ejaculate boss coffee last four years...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  find corpse vegetarian restaurant Bangkok find...      1\n",
       "1  switzerland warn authorize extradition politic...      1\n",
       "2  navarre censor Songs Amaral Shakira song Madma...      1\n",
       "3  woman pretend blind years greet people Now tru...      1\n",
       "4  arrested ejaculate boss coffee last four years...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame()\n",
    "dataset['text'] = join_lists(df, ['all_word'])\n",
    "dataset['label'] = df['fake']*1\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 6713)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv_values = cv.fit_transform(dataset['text'].values)\n",
    "cv_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split datasets in real and false\n",
    "df_train_real = df_train.loc[df_train['label'] == 0]\n",
    "df_train_fake = df_train.loc[df_train['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 6713) (57, 6713)\n"
     ]
    }
   ],
   "source": [
    "# 2. Transform each group from text to vocabulary\n",
    "cv_train_real = cv.transform(df_train_real['text'])\n",
    "cv_train_fake = cv.transform(df_train_fake['text'])\n",
    "print(cv_train_real.shape,cv_train_fake.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create TF-IDF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create models for each\n",
    "tfidf_model_real = TfidfTransformer(use_idf=True).fit(cv_train_real)\n",
    "tfidf_model_fake = TfidfTransformer(use_idf=True).fit(cv_train_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results, feature_vals\n",
    "\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Fake news relevant words\n",
    "We want to get the top relevant words of Fake News documents by the TF-IDF create, so we compute from fake news text to tfidf weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_words_fake_train = tfidf_model_fake.transform(cv_train_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will sort the words of dictionary by weitgh and get the top_n more relevant words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 200\n",
    "results_fake, top_fake_words = tf.get_topn_relevant_words(cv, tf_words_fake_train, topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items=sort_coo(tf_words_fake_train.tocoo())\n",
    "feature_names =cv.get_feature_names()\n",
    "results, top_fake_words = extract_topn_from_vector(feature_names, sorted_items, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rice': 0.689,\n",
       " 'cheese': 0.637,\n",
       " 'dog': 0.624,\n",
       " 'restaurant': 0.5,\n",
       " 'ikea': 0.5,\n",
       " 'switzerland': 0.481,\n",
       " 'crocodiles': 0.48,\n",
       " 'sexual': 0.458,\n",
       " 'foreign': 0.442,\n",
       " 'songs': 0.438,\n",
       " 'cor': 0.435,\n",
       " 'wax': 0.428,\n",
       " 'guitar': 0.424,\n",
       " 'day': 0.155,\n",
       " 'water': 0.152,\n",
       " 'beach': 0.41,\n",
       " 'echenique': 0.41,\n",
       " 'libya': 0.409,\n",
       " 'semen': 0.405,\n",
       " 'store': 0.4,\n",
       " 'prisoners': 0.379,\n",
       " 'alejandro': 0.395,\n",
       " 'blind': 0.39,\n",
       " 'museum': 0.385,\n",
       " 'pastor': 0.384,\n",
       " 'cold': 0.383,\n",
       " 'women': 0.202,\n",
       " 'drivers': 0.192,\n",
       " 'use': 0.149,\n",
       " 'military': 0.373,\n",
       " 'crush': 0.371,\n",
       " 'feminist': 0.37,\n",
       " 'ugly': 0.368,\n",
       " 'pp': 0.366,\n",
       " 'guindos': 0.36,\n",
       " 'melilla': 0.359,\n",
       " 'police': 0.153,\n",
       " 'forest': 0.355,\n",
       " 'minimum': 0.354,\n",
       " 'control': 0.206,\n",
       " 'vallecas': 0.346,\n",
       " 'office': 0.344,\n",
       " 'abedi': 0.341,\n",
       " 'children': 0.161,\n",
       " 'feminism': 0.34,\n",
       " 'cents': 0.337,\n",
       " 'airline': 0.337,\n",
       " 'muslim': 0.324,\n",
       " 'que': 0.163,\n",
       " 'wage': 0.322,\n",
       " 'madrid': 0.14,\n",
       " 'families': 0.321,\n",
       " 'extradition': 0.321,\n",
       " 'flag': 0.314,\n",
       " 'vagina': 0.314,\n",
       " 'parent': 0.314,\n",
       " 'german': 0.314,\n",
       " 'airport': 0.312,\n",
       " 'radar': 0.311,\n",
       " 'driver': 0.31,\n",
       " 'dgt': 0.31,\n",
       " 'burial': 0.308,\n",
       " 'license': 0.307,\n",
       " 'request': 0.305,\n",
       " 'figure': 0.304,\n",
       " 'young': 0.304,\n",
       " 'lover': 0.304,\n",
       " 'choke': 0.304,\n",
       " 'muslims': 0.151,\n",
       " 'maintainers': 0.302,\n",
       " 'benicarló': 0.302,\n",
       " 'drink': 0.301,\n",
       " 'actor': 0.3,\n",
       " 'immigrants': 0.298,\n",
       " 'spaniards': 0.297,\n",
       " 'vandalism': 0.296,\n",
       " 'plastic': 0.295,\n",
       " 'grain': 0.295,\n",
       " 'spanish': 0.242,\n",
       " 'six': 0.293,\n",
       " 'magi': 0.218,\n",
       " 'oxford': 0.29,\n",
       " 'voters': 0.29,\n",
       " 'devour': 0.288,\n",
       " 'card': 0.286,\n",
       " 'red': 0.286,\n",
       " 'thai': 0.286,\n",
       " 'poison': 0.285,\n",
       " 'oral': 0.285,\n",
       " 'security': 0.284,\n",
       " 'years': 0.255,\n",
       " 'scene': 0.279,\n",
       " 'de': 0.22,\n",
       " 'magazines': 0.278,\n",
       " 'obama': 0.278,\n",
       " 'diskjockey': 0.276,\n",
       " 'animal': 0.275,\n",
       " 'prosecutor': 0.275,\n",
       " 'gay': 0.274,\n",
       " 'officer': 0.169,\n",
       " 'manchester': 0.272,\n",
       " 'test': 0.153,\n",
       " 'council': 0.27,\n",
       " 'veil': 0.269,\n",
       " 'islamophobic': 0.269,\n",
       " 'study': 0.266,\n",
       " 'welcome': 0.266,\n",
       " 'aquarius': 0.266,\n",
       " 'inmates': 0.265,\n",
       " 'law': 0.265,\n",
       " 'lana': 0.264,\n",
       " 'baby': 0.264,\n",
       " 'rivera': 0.263,\n",
       " 'traffic': 0.261,\n",
       " 'pretend': 0.26,\n",
       " 'refugees': 0.26,\n",
       " 'cross': 0.26,\n",
       " 'catalan': 0.259,\n",
       " 'real': 0.259,\n",
       " 'right': 0.232,\n",
       " 'sanz': 0.257,\n",
       " 'masturbate': 0.257,\n",
       " 'die': 0.234,\n",
       " 'political': 0.254,\n",
       " 'ha': 0.253,\n",
       " 'sánchez': 0.253,\n",
       " 'sanchez': 0.253,\n",
       " 'economy': 0.253,\n",
       " 'tons': 0.252,\n",
       " 'agents': 0.251,\n",
       " 'local': 0.131,\n",
       " 'vistalegre': 0.247,\n",
       " 'priest': 0.247,\n",
       " 'nuns': 0.247,\n",
       " 'benevolent': 0.247,\n",
       " 'rescue': 0.247,\n",
       " 'usd': 0.245,\n",
       " 'jian': 0.245,\n",
       " 'irish': 0.245,\n",
       " 'feng': 0.245,\n",
       " 'europe': 0.245,\n",
       " 'comply': 0.244,\n",
       " 'space': 0.243,\n",
       " 'volunteer': 0.243,\n",
       " 'short': 0.243,\n",
       " 'huelva': 0.243,\n",
       " 'algerian': 0.243,\n",
       " 'walk': 0.242,\n",
       " 'mother': 0.241,\n",
       " 'mayor': 0.206,\n",
       " 'song': 0.238,\n",
       " 'truth': 0.236,\n",
       " 'greet': 0.236,\n",
       " 'toxic': 0.236,\n",
       " 'practise': 0.236,\n",
       " 'rotten': 0.235,\n",
       " 'pay': 0.148,\n",
       " 'civil': 0.234,\n",
       " 'agent': 0.233,\n",
       " 'degree': 0.233,\n",
       " 'bullfighting': 0.229,\n",
       " 'university': 0.142,\n",
       " 'pilot': 0.228,\n",
       " 'companion': 0.228,\n",
       " 'tres': 0.227,\n",
       " 'cantos': 0.227,\n",
       " 'offense': 0.227,\n",
       " 'recover': 0.226,\n",
       " 'merchandise': 0.226,\n",
       " 'mountains': 0.226,\n",
       " 'guardia': 0.226,\n",
       " 'toilet': 0.225,\n",
       " 'swoop': 0.225,\n",
       " 'canadian': 0.225,\n",
       " 'minister': 0.191,\n",
       " 'pass': 0.224,\n",
       " 'wife': 0.145,\n",
       " 'city': 0.224,\n",
       " 'diputación': 0.223,\n",
       " 'put': 0.223,\n",
       " 'sue': 0.163,\n",
       " 'trump': 0.222,\n",
       " 'hispanic': 0.222,\n",
       " 'charge': 0.221,\n",
       " 'prisons': 0.221,\n",
       " 'pedro': 0.221,\n",
       " 'steal': 0.221,\n",
       " 'en': 0.22,\n",
       " 'end': 0.22,\n",
       " 'believe': 0.219,\n",
       " 'pride': 0.219,\n",
       " 'discover': 0.219,\n",
       " 'night': 0.218,\n",
       " 'subcontract': 0.217,\n",
       " 'pucherazo': 0.217,\n",
       " 'headquarter': 0.215,\n",
       " 'vegetarian': 0.214,\n",
       " 'flesh': 0.214,\n",
       " 'swiss': 0.214,\n",
       " 'invite': 0.186,\n",
       " 'islamic': 0.151,\n",
       " 'offer': 0.21,\n",
       " 'open': 0.21,\n",
       " 'gonzalez': 0.209,\n",
       " 'child': 0.209,\n",
       " 'father': 0.14,\n",
       " 'months': 0.208,\n",
       " 'prat': 0.208,\n",
       " 'bodyguards': 0.208,\n",
       " 'iglesias': 0.208,\n",
       " 'church': 0.208,\n",
       " 'woman': 0.167,\n",
       " 'breathalyzer': 0.207,\n",
       " 'enable': 0.206,\n",
       " 'unemployed': 0.206,\n",
       " 'mili': 0.206,\n",
       " 'inem': 0.206,\n",
       " 'state': 0.187,\n",
       " 'seize': 0.205,\n",
       " 'counterfeit': 0.205,\n",
       " 'satellite': 0.205,\n",
       " 'navigation': 0.205,\n",
       " 'movie': 0.205,\n",
       " 'bmw': 0.205,\n",
       " 'management': 0.205,\n",
       " 'salamanca': 0.205,\n",
       " 'file': 0.205,\n",
       " 'apartment': 0.205,\n",
       " 'libyan': 0.204,\n",
       " 'user': 0.204,\n",
       " 'bathroom': 0.181,\n",
       " 'time': 0.204,\n",
       " 'new': 0.139,\n",
       " 'burn': 0.179,\n",
       " 'phone': 0.203,\n",
       " 'hotel': 0.203,\n",
       " 'financial': 0.202,\n",
       " 'shit': 0.202,\n",
       " 'article': 0.201,\n",
       " 'international': 0.201,\n",
       " 'facilities': 0.2,\n",
       " 'client': 0.2,\n",
       " 'white': 0.198,\n",
       " 'account': 0.198,\n",
       " 'men': 0.14,\n",
       " 'well': 0.198,\n",
       " 'association': 0.163,\n",
       " 'election': 0.197,\n",
       " 'character': 0.197,\n",
       " 'pablo': 0.195,\n",
       " 'public': 0.195,\n",
       " 'another': 0.195,\n",
       " 'nationalities': 0.195,\n",
       " 'family': 0.194,\n",
       " 'responses': 0.193,\n",
       " 'math': 0.193,\n",
       " 'la': 0.155,\n",
       " 'hortel': 0.193,\n",
       " 'shepherd': 0.192,\n",
       " 'river': 0.192,\n",
       " 'mthethwa': 0.192,\n",
       " 'jonathan': 0.192,\n",
       " 'violence': 0.191,\n",
       " 'calvo': 0.191,\n",
       " 'valenciana': 0.191,\n",
       " 'syrian': 0.191,\n",
       " 'flat': 0.191,\n",
       " 'authorization': 0.191,\n",
       " 'accessible': 0.191,\n",
       " 'albert': 0.189,\n",
       " 'people': 0.139,\n",
       " 'racial': 0.187,\n",
       " 'vehicles': 0.186,\n",
       " 'heaven': 0.186,\n",
       " 'belong': 0.186,\n",
       " 'enjoy': 0.186,\n",
       " 'his': 0.185,\n",
       " 'collection': 0.185,\n",
       " 'kingdom': 0.185,\n",
       " 'support': 0.154,\n",
       " 'point': 0.185,\n",
       " 'tradition': 0.185,\n",
       " 'president': 0.146,\n",
       " 'demonstration': 0.183,\n",
       " 'third': 0.183,\n",
       " 'must': 0.169,\n",
       " 'work': 0.181,\n",
       " 'celebrate': 0.181,\n",
       " 'strasbourg': 0.18,\n",
       " 'processions': 0.18,\n",
       " 'iranian': 0.18,\n",
       " 'easter': 0.18,\n",
       " 'man': 0.147,\n",
       " 'say': 0.179,\n",
       " 'uned': 0.179,\n",
       " 'mouthpieces': 0.179,\n",
       " 'mouthpiece': 0.179,\n",
       " 'breathalyzers': 0.179,\n",
       " 'colau': 0.177,\n",
       " 'ada': 0.177,\n",
       " 'sex': 0.176,\n",
       " 'we': 0.176,\n",
       " 'strong': 0.176,\n",
       " 'abort': 0.176,\n",
       " 'legal': 0.175,\n",
       " 'review': 0.175,\n",
       " 'handle': 0.175,\n",
       " 'you': 0.175,\n",
       " 'shakira': 0.175,\n",
       " 'navarra': 0.175,\n",
       " 'martín': 0.175,\n",
       " 'madman': 0.175,\n",
       " 'machists': 0.175,\n",
       " 'machismo': 0.175,\n",
       " 'dani': 0.175,\n",
       " 'amaral': 0.175,\n",
       " 'cause': 0.144,\n",
       " 'followers': 0.174,\n",
       " 'sexist': 0.154,\n",
       " 'carmen': 0.173,\n",
       " 'queen': 0.173,\n",
       " 'parade': 0.173,\n",
       " 'chariot': 0.173,\n",
       " 'disable': 0.173,\n",
       " 'merkel': 0.173,\n",
       " 'debate': 0.173,\n",
       " 'secretary': 0.172,\n",
       " 'municipal': 0.172,\n",
       " 'district': 0.172,\n",
       " 'condition': 0.172,\n",
       " 'air': 0.172,\n",
       " 'united': 0.172,\n",
       " 'british': 0.172,\n",
       " 'express': 0.172,\n",
       " 'change': 0.131,\n",
       " 'statue': 0.171,\n",
       " 'jorge': 0.171,\n",
       " 'hospitalet': 0.17,\n",
       " 'feces': 0.17,\n",
       " 'el': 0.17,\n",
       " 'animals': 0.17,\n",
       " 'playing': 0.17,\n",
       " 'body': 0.17,\n",
       " 'human': 0.169,\n",
       " 'smell': 0.168,\n",
       " 'attack': 0.136,\n",
       " 'plug': 0.168,\n",
       " 'placement': 0.168,\n",
       " 'begoña': 0.168,\n",
       " 'badajoz': 0.168,\n",
       " 'think': 0.167,\n",
       " 'world': 0.167,\n",
       " 'republican': 0.167,\n",
       " 'prison': 0.135,\n",
       " 'del': 0.165,\n",
       " 'wear': 0.164,\n",
       " 'fascist': 0.164,\n",
       " 'population': 0.164,\n",
       " 'times': 0.163,\n",
       " 'list': 0.159,\n",
       " 'religion': 0.163,\n",
       " 'faith': 0.163,\n",
       " 'teachers': 0.163,\n",
       " 'computer': 0.163,\n",
       " 'close': 0.162,\n",
       " 'important': 0.162,\n",
       " 'amount': 0.134,\n",
       " 'organization': 0.162,\n",
       " 'montes': 0.161,\n",
       " 'temporary': 0.161,\n",
       " 'permit': 0.161,\n",
       " 'deputy': 0.161,\n",
       " 'spf': 0.161,\n",
       " 'prisoner': 0.161,\n",
       " 'famous': 0.161,\n",
       " 'generalitat': 0.161,\n",
       " 'start': 0.16,\n",
       " 'gabriel': 0.16,\n",
       " 'eventual': 0.16,\n",
       " 'anna': 0.16,\n",
       " 'serve': 0.16,\n",
       " 'husband': 0.16,\n",
       " 'topics': 0.151,\n",
       " 'program': 0.159,\n",
       " 'house': 0.159,\n",
       " 'research': 0.158,\n",
       " 'need': 0.158,\n",
       " 'malaga': 0.158,\n",
       " 'friend': 0.158,\n",
       " 'drag': 0.157,\n",
       " 'cavalcade': 0.157,\n",
       " 'carmena': 0.157,\n",
       " 'unusual': 0.157,\n",
       " 'sustacia': 0.157,\n",
       " 'suspicion': 0.157,\n",
       " 'negro': 0.157,\n",
       " 'model': 0.157,\n",
       " 'view': 0.157,\n",
       " 'racist': 0.157,\n",
       " 'custody': 0.157,\n",
       " 'popular': 0.157,\n",
       " 'liturgies': 0.157,\n",
       " 'random': 0.156,\n",
       " 'explosives': 0.156,\n",
       " 'good': 0.156,\n",
       " 'announce': 0.155,\n",
       " 'neighbor': 0.155,\n",
       " 'garcia': 0.155,\n",
       " 'reject': 0.154,\n",
       " 'approve': 0.143,\n",
       " 'abuse': 0.154,\n",
       " 'find': 0.15,\n",
       " 'christians': 0.154,\n",
       " 'image': 0.154,\n",
       " 'car': 0.154,\n",
       " 'observatory': 0.153,\n",
       " 'mockery': 0.153,\n",
       " 'bully': 0.153,\n",
       " 'stress': 0.153,\n",
       " 'minutes': 0.153,\n",
       " 'gender': 0.153,\n",
       " 'gómez': 0.152,\n",
       " 'david': 0.152,\n",
       " 'agency': 0.152,\n",
       " 'death': 0.152,\n",
       " 'issue': 0.151,\n",
       " 'describe': 0.151,\n",
       " 'storm': 0.151,\n",
       " 'premise': 0.151,\n",
       " 'confiscate': 0.151,\n",
       " 'chaos': 0.151,\n",
       " 'september': 0.15,\n",
       " 'rate': 0.15,\n",
       " 'government': 0.135,\n",
       " 'measure': 0.135,\n",
       " 'social': 0.148,\n",
       " 'launch': 0.148,\n",
       " 'hate': 0.148,\n",
       " 'promote': 0.147,\n",
       " 'high': 0.147,\n",
       " 'former': 0.147,\n",
       " 'party': 0.147,\n",
       " 'able': 0.147,\n",
       " 'interior': 0.146,\n",
       " 'foreigners': 0.146,\n",
       " 'two': 0.146,\n",
       " 'take': 0.134,\n",
       " 'successful': 0.145,\n",
       " 'orientation': 0.145,\n",
       " 'galician': 0.145,\n",
       " 'clauses': 0.145,\n",
       " 'insolidarity': 0.145,\n",
       " 'prasit': 0.143,\n",
       " 'meat': 0.143,\n",
       " 'bangkok': 0.143,\n",
       " 'power': 0.143,\n",
       " 'impregnate': 0.142,\n",
       " 'assassination': 0.142,\n",
       " 'respect': 0.142,\n",
       " 'hand': 0.142,\n",
       " 'throughout': 0.142,\n",
       " 'islam': 0.142,\n",
       " 'torra': 0.141,\n",
       " 'race': 0.141,\n",
       " 'catalans': 0.141,\n",
       " 'link': 0.14,\n",
       " 'would': 0.134,\n",
       " 'commit': 0.14,\n",
       " 'generate': 0.14,\n",
       " 'king': 0.14,\n",
       " 'fully': 0.14,\n",
       " 'bring': 0.139,\n",
       " 'polo': 0.139,\n",
       " 'declarant': 0.139,\n",
       " 'bar': 0.139,\n",
       " 'almería': 0.139,\n",
       " 'inclusive': 0.139,\n",
       " 'celebration': 0.139,\n",
       " 'slowly': 0.138,\n",
       " 'slow': 0.138,\n",
       " 'punch': 0.138,\n",
       " 'pounce': 0.138,\n",
       " 'nightclub': 0.138,\n",
       " 'logroño': 0.138,\n",
       " 'heavy': 0.138,\n",
       " 'grandstand': 0.138,\n",
       " 'fonsi': 0.138,\n",
       " 'exalted': 0.138,\n",
       " 'endure': 0.138,\n",
       " 'dj': 0.138,\n",
       " 'disco': 0.138,\n",
       " 'defiant': 0.138,\n",
       " 'climb': 0.138,\n",
       " 'basto': 0.138,\n",
       " 'case': 0.138,\n",
       " 'try': 0.138,\n",
       " 'rebuke': 0.137,\n",
       " 'special': 0.136,\n",
       " 'guard': 0.136,\n",
       " 'bomb': 0.136,\n",
       " 'require': 0.136,\n",
       " 'hunt': 0.136,\n",
       " 'assistance': 0.135,\n",
       " 'every': 0.135,\n",
       " 'leave': 0.131,\n",
       " 'citizens': 0.135,\n",
       " 'create': 0.134,\n",
       " 'true': 0.134,\n",
       " 'presence': 0.134,\n",
       " 'statistics': 0.133,\n",
       " 'compare': 0.133,\n",
       " 'controversial': 0.132,\n",
       " 'brother': 0.132,\n",
       " 'victim': 0.132,\n",
       " 'attempt': 0.132,\n",
       " 'health': 0.132,\n",
       " 'framework': 0.132,\n",
       " 'discrimination': 0.132,\n",
       " 'direct': 0.132,\n",
       " 'progressive': 0.131,\n",
       " 'frighten': 0.131,\n",
       " 'cut': 0.131,\n",
       " 'coordinator': 0.131,\n",
       " 'trade': 0.131,\n",
       " 'alternative': 0.131,\n",
       " 'school': 0.131}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Real news relevant words\n",
    "It needs to do the same process but with real news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_words_real_train = tfidf_model_real.transform(cv_train_real)\n",
    "topn = 200\n",
    "results_real, top_real_words = tf.get_topn_relevant_words(cv, tf_words_real_train, topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bitcoin': 0.766,\n",
       " 'mw': 0.578,\n",
       " 'columbus': 0.495,\n",
       " 'attack': 0.478,\n",
       " 'purchase': 0.264,\n",
       " 'bbva': 0.406,\n",
       " 'maroto': 0.442,\n",
       " 'vox': 0.439,\n",
       " 'education': 0.437,\n",
       " 'bettong': 0.426,\n",
       " 'degree': 0.423,\n",
       " 'valeria': 0.418,\n",
       " 'frb': 0.414,\n",
       " 'burst': 0.414,\n",
       " 'passengers': 0.409,\n",
       " 'calviño': 0.406,\n",
       " 'manicure': 0.4,\n",
       " 'listen': 0.399,\n",
       " 'operations': 0.382,\n",
       " 'sesame': 0.379,\n",
       " 'netflix': 0.355,\n",
       " 'price': 0.237,\n",
       " 'catalonia': 0.353,\n",
       " 'borrell': 0.351,\n",
       " 'waistcoats': 0.351,\n",
       " 'liceu': 0.349,\n",
       " 'conservatory': 0.349,\n",
       " 'statue': 0.347,\n",
       " 'bet': 0.344,\n",
       " 'liter': 0.341,\n",
       " 'abascal': 0.334,\n",
       " 'choke': 0.333,\n",
       " 'congress': 0.244,\n",
       " 'death': 0.328,\n",
       " 'survivors': 0.326,\n",
       " 'political': 0.324,\n",
       " 'motion': 0.324,\n",
       " 'washington': 0.323,\n",
       " 'panda': 0.323,\n",
       " 'giant': 0.323,\n",
       " 'syria': 0.321,\n",
       " 'ambulances': 0.321,\n",
       " 'cuba': 0.32,\n",
       " 'movistar': 0.319,\n",
       " 'workers': 0.318,\n",
       " 'yellow': 0.318,\n",
       " 'authority': 0.317,\n",
       " 'january': 0.315,\n",
       " 'unemployment': 0.311,\n",
       " 'artists': 0.305,\n",
       " 'disinformation': 0.305,\n",
       " 'hathaway': 0.303,\n",
       " 'moreno': 0.303,\n",
       " 'xiaomi': 0.302,\n",
       " 'ikea': 0.302,\n",
       " 'introduce': 0.3,\n",
       " 'plaque': 0.299,\n",
       " 'quer': 0.298,\n",
       " 'wilson': 0.296,\n",
       " 'abuse': 0.296,\n",
       " 'sport': 0.295,\n",
       " 'coward': 0.295,\n",
       " 'payton': 0.295,\n",
       " 'fox': 0.295,\n",
       " 'refugees': 0.294,\n",
       " 'foreigners': 0.294,\n",
       " 'ryanair': 0.292,\n",
       " 'aviation': 0.292,\n",
       " 'radio': 0.292,\n",
       " 'fine': 0.291,\n",
       " 'private': 0.29,\n",
       " 'patrol': 0.289,\n",
       " 'gibraltar': 0.289,\n",
       " 'wind': 0.289,\n",
       " 'offshore': 0.289,\n",
       " 'zarzuela': 0.282,\n",
       " 'employment': 0.282,\n",
       " 'euros': 0.279,\n",
       " 'elections': 0.279,\n",
       " 'hanukkah': 0.279,\n",
       " 'law': 0.279,\n",
       " 'health': 0.279,\n",
       " 'ot': 0.278,\n",
       " 'pp': 0.277,\n",
       " 'crime': 0.276,\n",
       " 'film': 0.274,\n",
       " 'chinese': 0.273,\n",
       " 'petrol': 0.273,\n",
       " 'diesel': 0.273,\n",
       " 'european': 0.228,\n",
       " 'center': 0.27,\n",
       " 'detect': 0.27,\n",
       " 'city': 0.269,\n",
       " 'brexit': 0.268,\n",
       " 'italian': 0.266,\n",
       " 'habitat': 0.266,\n",
       " 'psoe': 0.265,\n",
       " 'korea': 0.264,\n",
       " 'japanese': 0.264,\n",
       " 'japan': 0.264,\n",
       " 'dissolve': 0.264,\n",
       " 'stab': 0.264,\n",
       " 'paris': 0.263,\n",
       " 'project': 0.263,\n",
       " 'online': 0.262,\n",
       " 'water': 0.262,\n",
       " 'roger': 0.262,\n",
       " 'fund': 0.261,\n",
       " 'home': 0.261,\n",
       " 'technical': 0.255,\n",
       " 'advantage': 0.253,\n",
       " 'products': 0.212,\n",
       " 'statute': 0.251,\n",
       " 'game': 0.25,\n",
       " 'telefónica': 0.248,\n",
       " 'cs': 0.248,\n",
       " 'sabela': 0.247,\n",
       " 'red': 0.247,\n",
       " 'script': 0.245,\n",
       " 'googletag': 0.245,\n",
       " 'store': 0.244,\n",
       " 'pdecat': 0.244,\n",
       " 'urkullu': 0.243,\n",
       " 'sant': 0.242,\n",
       " 'joan': 0.242,\n",
       " 'despí': 0.242,\n",
       " 'basque': 0.241,\n",
       " 'personal': 0.24,\n",
       " 'enjoy': 0.24,\n",
       " 'data': 0.239,\n",
       " 'carlos': 0.239,\n",
       " 'south': 0.239,\n",
       " 'fuel': 0.238,\n",
       " 'parliament': 0.236,\n",
       " 'agreement': 0.236,\n",
       " 'civil': 0.234,\n",
       " 'communities': 0.233,\n",
       " 'yolanda': 0.232,\n",
       " 'cover': 0.232,\n",
       " 'infanta': 0.232,\n",
       " 'elena': 0.232,\n",
       " 'cross': 0.231,\n",
       " 'week': 0.23,\n",
       " 'news': 0.23,\n",
       " 'buy': 0.229,\n",
       " 'oil': 0.228,\n",
       " 'actress': 0.227,\n",
       " 'monarch': 0.225,\n",
       " 'emeritus': 0.225,\n",
       " 'football': 0.225,\n",
       " 'brand': 0.224,\n",
       " 'villarejo': 0.224,\n",
       " 'supreme': 0.223,\n",
       " 'may': 0.223,\n",
       " 'spokespersons': 0.223,\n",
       " 'bosquet': 0.223,\n",
       " 'time': 0.223,\n",
       " 'president': 0.223,\n",
       " 'object': 0.222,\n",
       " 'church': 0.222,\n",
       " 'king': 0.221,\n",
       " 'morning': 0.221,\n",
       " 'retain': 0.219,\n",
       " 'motónity': 0.218,\n",
       " 'motorcycle': 0.218,\n",
       " 'electoral': 0.217,\n",
       " 'jury': 0.216,\n",
       " 'gala': 0.216,\n",
       " 'zoo': 0.215,\n",
       " 'storm': 0.215,\n",
       " 'snow': 0.215,\n",
       " 'bei': 0.215,\n",
       " 'post': 0.215,\n",
       " 'malone': 0.215,\n",
       " 'police': 0.214,\n",
       " 'neighbor': 0.214,\n",
       " 'countries': 0.213,\n",
       " 'merger': 0.213,\n",
       " 'fusion': 0.213,\n",
       " 'black': 0.212,\n",
       " 'network': 0.212,\n",
       " 'usd': 0.211,\n",
       " 'economy': 0.21,\n",
       " 'finance': 0.209,\n",
       " 'cause': 0.208,\n",
       " 'wikinger': 0.207,\n",
       " 'students': 0.206,\n",
       " 'barcelona': 0.206,\n",
       " 'rebound': 0.204,\n",
       " 'dollars': 0.204,\n",
       " 'russia': 0.203,\n",
       " 'mossos': 0.203,\n",
       " 'marta': 0.202,\n",
       " 'juanma': 0.202}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Transform to TF-IDF test data for future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But first translate to tfdif encoding test data\n",
    "# 1. Split\n",
    "df_test_real = df_test.loc[df_test['label'] == 0]\n",
    "df_test_fake = df_test.loc[df_test['label'] == 1]\n",
    "# 2. To count vectorizer\n",
    "cv_test_real = cv.transform(df_test_real['text'].values)\n",
    "cv_test_fake = cv.transform(df_test_fake['text'].values)\n",
    "\n",
    "# 3. To tfidf\n",
    "tf_words_real_test = tfidf_model_real.transform(cv_test_real)\n",
    "tf_words_fake_test = tfidf_model_fake.transform(cv_test_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Compute cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "def get_cosine_similarity(q1_csc, q2_csc):\n",
    "    cosine_sim = []\n",
    "    for i,j in zip(q1_csc, q2_csc):\n",
    "        sim = cs(i,j)\n",
    "        cosine_sim.append(sim[0][0])\n",
    "    \n",
    "    return cosine_sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_real_words_coded = cv.transform([' '.join(top_real_words)])\n",
    "top_fake_words_coded = cv.transform([' '.join(top_fake_words)])\n",
    "df_train['cv_value'] = cv.transform(df_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['cos_fake'] = df_train['label']*0.000000000005\n",
    "df_train['cos_real'] = df_train['label']*0.000000000005\n",
    "for index, row in df_train.iterrows():\n",
    "    to_number = cv.transform([row['text']])\n",
    "    cosine_sim_fake = get_cosine_similarity(top_fake_words_coded, to_number)\n",
    "    cosine_sim_real = get_cosine_similarity(top_real_words_coded, to_number)\n",
    "    df_train.at[index,'cos_fake'] = cosine_sim_fake[0]\n",
    "    df_train.at[index,'cos_real'] = cosine_sim_real[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_real</th>\n",
       "      <th>cos_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.030054</td>\n",
       "      <td>0.154907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.089502</td>\n",
       "      <td>0.147831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.108463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.024804</td>\n",
       "      <td>0.142764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.035079</td>\n",
       "      <td>0.141631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cos_real  cos_fake\n",
       "10   0.030054  0.154907\n",
       "130  0.089502  0.147831\n",
       "51   0.019130  0.108463\n",
       "11   0.024804  0.142764\n",
       "114  0.035079  0.141631"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['cos_real', 'cos_fake']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification\n",
    "### 6.1 Get optimal top_n words to classify with SVM\n",
    "\n",
    "After show the process of how create two list of relevant words for each type of news, it is now implement on function `get_relevant_word_lists` which return both lists, from real and from fake. The important input for the function is `top_n` where will be variable and test on SVM models to see with which value the model can classify better the articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we process to implement a loop of SVM trainings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_values = list(range(50, 4000, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = df_train['label'].values\n",
    "y_test = df_test['label'].values\n",
    "X_train = df_train[['cos_real', 'cos_fake']].values\n",
    "X_test = df_test[['cos_real', 'cos_fake']].values\n",
    "    \n",
    "all_scores = []\n",
    "for top_n in top_n_values:\n",
    "    res, top_real_words = t.get_topn_relevant_words(cv, tf_train_real, top_n)\n",
    "    res, top_fake_words = t.get_topn_relevant_words(cv, tf_train_fake, top_n)\n",
    "    # Encode top words\n",
    "    cv_top_real_words = cv.transform([' '.join(top_real_words)])\n",
    "    cv_top_fake_words = cv.transform([' '.join(top_fake_words)])\n",
    "    \n",
    "    # Cosine similarity of train\n",
    "    compute_similarity(df_train, cv, cv_top_real_words, cv_top_fake_words)\n",
    "    # Cosine similarity of text\n",
    "    compute_similarity(df_test, cv, cv_top_real_words, cv_top_fake_words)\n",
    "    \n",
    "    # Update X values\n",
    "    X_train = df_train[['cos_real', 'cos_fake']].values\n",
    "    X_test = df_test[['cos_real', 'cos_fake']].values\n",
    "    # Run SVM\n",
    "    scores = svm_controller.run_optimals_models(X_train, y_train, X_test, y_test, False)\n",
    "    scores.append(top_n) \n",
    "    all_scores.append(scores)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(data=all_scores, columns=['kernel_training', 'training', 'kernel_validation', 'validation', 'top_n'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.sort_values(['validation'], ascending=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, Y_test\n",
    "\n",
    "aranged_pc1 = np.arange(start = X_set[:, 0].min(), stop = X_set[:, 0].max(), step = 0.01)\n",
    "aranged_pc2 = np.arange(start = X_set[:, 1].min(), stop = X_set[:, 1].max(), step = 0.01)\n",
    "\n",
    "X1, X2 = np.meshgrid(aranged_pc1, aranged_pc2)\n",
    "plt.contourf(X1, X2, models['rbf'].predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "alpha = 0.5, cmap = ListedColormap(('orange', 'green')))\n",
    "\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('SVM prediction from LDA transformation')\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
