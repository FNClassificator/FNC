{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: BOW/TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for Jupyter Notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.utils import io\n",
    "\n",
    "from src.fake_news_detector.core.encoders import bow as b\n",
    "from src.fake_news_detector.core.encoders import tfidf as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import `dataset_raw.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/dataset_content.json')\n",
    "df = pd.DataFrame(data=articles['articles']) # Put in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_joined</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>adjective_words</th>\n",
       "      <th>noun_phrases_words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Thai police have clarified to the middle A...</td>\n",
       "      <td>[like]</td>\n",
       "      <td>[corpse, kill, fire, complain, deny, victim, v...</td>\n",
       "      <td>[vegetarian, international, human, middle, ope...</td>\n",
       "      <td>[corpse, vegetarian restaurant, Bangkok, find,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swiss government has said Tuesday that \"a ...</td>\n",
       "      <td>[Justice, like, Supreme, fair, perfectly]</td>\n",
       "      <td>[no, stress, offences, offences, accuse, argue...</td>\n",
       "      <td>[political, Swiss, legal, eventual, underline,...</td>\n",
       "      <td>[switzerland warn, extradition, political crim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Government of Navarra, within the Skolae p...</td>\n",
       "      <td>[promote, great, hope, promote, like, affectio...</td>\n",
       "      <td>[censor, violence, ban, bad, fight, shit]</td>\n",
       "      <td>[navarre, educational, several, great, last, f...</td>\n",
       "      <td>[navarre censor Songs, Amaral Shakira, song, M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carmen Jiménez told her family and friends 28 ...</td>\n",
       "      <td>[greet, truth, friends, truth, greet, justice]</td>\n",
       "      <td>[blind, blind, injury, blind, avoid]</td>\n",
       "      <td>[Spanish, i, social, pose, many, hard, whole, ...</td>\n",
       "      <td>[woman pretend, years, people, truth, Carmen J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lewis Williams, a worker at an engineering fir...</td>\n",
       "      <td>[United, strong, superior, proud]</td>\n",
       "      <td>[arrested, detain, arrest, prison, abuse]</td>\n",
       "      <td>[last, past, despicable, strong, superior, ass...</td>\n",
       "      <td>[ejaculate, boss coffee, years, action, discus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          all_joined  \\\n",
       "0  The Thai police have clarified to the middle A...   \n",
       "1  The Swiss government has said Tuesday that \"a ...   \n",
       "2  The Government of Navarra, within the Skolae p...   \n",
       "3  Carmen Jiménez told her family and friends 28 ...   \n",
       "4  Lewis Williams, a worker at an engineering fir...   \n",
       "\n",
       "                                      positive_words  \\\n",
       "0                                             [like]   \n",
       "1          [Justice, like, Supreme, fair, perfectly]   \n",
       "2  [promote, great, hope, promote, like, affectio...   \n",
       "3     [greet, truth, friends, truth, greet, justice]   \n",
       "4                  [United, strong, superior, proud]   \n",
       "\n",
       "                                      negative_words  \\\n",
       "0  [corpse, kill, fire, complain, deny, victim, v...   \n",
       "1  [no, stress, offences, offences, accuse, argue...   \n",
       "2          [censor, violence, ban, bad, fight, shit]   \n",
       "3               [blind, blind, injury, blind, avoid]   \n",
       "4          [arrested, detain, arrest, prison, abuse]   \n",
       "\n",
       "                                     adjective_words  \\\n",
       "0  [vegetarian, international, human, middle, ope...   \n",
       "1  [political, Swiss, legal, eventual, underline,...   \n",
       "2  [navarre, educational, several, great, last, f...   \n",
       "3  [Spanish, i, social, pose, many, hard, whole, ...   \n",
       "4  [last, past, despicable, strong, superior, ass...   \n",
       "\n",
       "                                  noun_phrases_words  label  \n",
       "0  [corpse, vegetarian restaurant, Bangkok, find,...      1  \n",
       "1  [switzerland warn, extradition, political crim...      1  \n",
       "2  [navarre censor Songs, Amaral Shakira, song, M...      1  \n",
       "3  [woman pretend, years, people, truth, Carmen J...      1  \n",
       "4  [ejaculate, boss coffee, years, action, discus...      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get useful info from our dataset:\n",
    "dataset = pd.DataFrame()\n",
    "list_f = ['all_joined', 'positive_words', 'negative_words', 'adjective_words', 'noun_phrases_words']\n",
    "dataset = df[list_f]\n",
    "dataset['label'] = df['fake']*1\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dictionary creation and word vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_lists(dataset, word_lists):\n",
    "    result = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        text_join = \"\"\n",
    "        for feature in word_lists:\n",
    "            doc_list = row[feature]\n",
    "            text_join += ' '.join(doc_list)\n",
    "        result.append(text_join)\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 TF-IDF for all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "X_train = df_train['all_joined'].values\n",
    "Y_train = df_train['label'].values\n",
    "X_test = df_test['all_joined'].values\n",
    "Y_test = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 6505)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train_counts = cv.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 6505)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 TF-IDF for sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sent = join_lists(df_train, ['positive_words', 'negative_words'])\n",
    "Y_train = df_train['label'].values\n",
    "X_test_sent = join_lists(df_test, ['positive_words', 'negative_words'])\n",
    "Y_test = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 648)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sent = CountVectorizer()\n",
    "X_train_counts_sent = cv_sent.fit_transform(X_train_sent)\n",
    "X_train_counts_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 648)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer_sent = TfidfTransformer(use_idf=True).fit(X_train_counts_sent)\n",
    "X_train_tf_sent = tf_transformer_sent.transform(X_train_counts_sent)\n",
    "X_train_tf_sent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 TF-IDF withoun conjuntion and preposition words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['adjective_words', 'noun_phrases_words']\n",
    "X_train_word = join_lists(df_train, label_list)\n",
    "Y_train = df_train['label'].values\n",
    "X_test_word = join_lists(df_test, label_list)\n",
    "Y_test = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 648)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word = CountVectorizer()\n",
    "X_train_counts_word = cv_word.fit_transform(X_train_sent)\n",
    "X_train_counts_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 648)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer_word = TfidfTransformer(use_idf=True).fit(X_train_counts_word)\n",
    "X_train_tf_word = tf_transformer_word.transform(X_train_counts_word)\n",
    "X_train_tf_word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from src.fake_news_detector.core.classificators import SupportVectorMachine as s\n",
    "from src.fake_news_detector.core.classificators import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds, kernel):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel=kernel), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 TF-IDF all text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Tranform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 6505)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts = cv.transform(X_test)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "X_test_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Search best parameters for SVC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rbf: {'C': 10, 'gamma': 0.1}\n",
      "For linear: {'C': 10, 'gamma': 0.001}\n",
      "For poly: {'C': 10, 'gamma': 1}\n",
      "For sigmoid: {'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print('For rbf:', svc_param_selection(X_train_tf, Y_train, 2, 'rbf'))\n",
    "print('For linear:', svc_param_selection(X_train_tf, Y_train, 2, 'linear'))\n",
    "print('For poly:', svc_param_selection(X_train_tf, Y_train, 2, 'poly'))\n",
    "print('For sigmoid:', svc_param_selection(X_train_tf, Y_train, 2, 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['rbf'] = svm.SVC(kernel='rbf', C= 10, gamma=0.1)\n",
    "models['linear']  = svm.SVC(kernel='linear', C= 10, gamma=0.001)\n",
    "models['poly']  = svm.SVC(kernel='poly', C= 10, gamma=1)\n",
    "models['sigmoid'] = svm.SVC(kernel='sigmoid', C= 10, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model rbf\n",
      "Training score: 0.9888888888888889. Test score: 0.7142857142857143\n",
      "For model linear\n",
      "Training score: 0.9888888888888889. Test score: 0.7142857142857143\n",
      "For model poly\n",
      "Training score: 0.9888888888888889. Test score: 0.625\n",
      "For model sigmoid\n",
      "Training score: 0.9888888888888889. Test score: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "scores = s.run_models(models, X_train_tf, Y_train, X_test_tf, Y_test)\n",
    "for model in scores:\n",
    "    print('For model', model)\n",
    "    print('Training score: {}. Test score: {}'.format(scores[model]['train'],scores[model]['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 TF-IDF positive and negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Tranform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 648)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts_sent = cv_sent.transform(X_test_sent)\n",
    "X_test_tf_sent = tf_transformer_sent.transform(X_test_counts_sent)\n",
    "X_test_tf_sent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Search best parameters for SVC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rbf: {'C': 10, 'gamma': 0.1}\n",
      "For linear: {'C': 1, 'gamma': 0.001}\n",
      "For poly: {'C': 0.001, 'gamma': 0.001}\n",
      "For sigmoid: {'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print('For rbf:', svc_param_selection(X_train_tf_sent, Y_train, 2, 'rbf'))\n",
    "print('For linear:', svc_param_selection(X_train_tf_sent, Y_train, 2, 'linear'))\n",
    "print('For poly:', svc_param_selection(X_train_tf_sent, Y_train, 2, 'poly'))\n",
    "print('For sigmoid:', svc_param_selection(X_train_tf_sent, Y_train, 2, 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['rbf'] = svm.SVC(kernel='rbf', C= 10, gamma=0.1)\n",
    "models['linear']  = svm.SVC(kernel='linear', C= 1, gamma=0.001)\n",
    "models['poly']  = svm.SVC(kernel='poly', C= 0.001, gamma=0.001)\n",
    "models['sigmoid'] = svm.SVC(kernel='sigmoid', C= 10, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model rbf\n",
      "Training score: 0.9888888888888889. Test score: 0.5384615384615384\n",
      "For model linear\n",
      "Training score: 0.9888888888888889. Test score: 0.5\n",
      "For model poly\n",
      "Training score: 0.5555555555555556. Test score: 0.5217391304347826\n",
      "For model sigmoid\n",
      "Training score: 0.9888888888888889. Test score: 0.5\n"
     ]
    }
   ],
   "source": [
    "scores = s.run_models(models, X_train_tf_sent, Y_train, X_test_tf_sent, Y_test)\n",
    "for model in scores:\n",
    "    print('For model', model)\n",
    "    print('Training score: {}. Test score: {}'.format(scores[model]['train'],scores[model]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 648)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts_word = cv_word.transform(X_test_word)\n",
    "X_test_tf_word = tf_transformer_word.transform(X_test_counts_word)\n",
    "X_test_tf_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rbf: {'C': 10, 'gamma': 0.1}\n",
      "For linear: {'C': 10, 'gamma': 0.001}\n",
      "For poly: {'C': 0.001, 'gamma': 0.001}\n",
      "For sigmoid: {'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print('For rbf:', svc_param_selection(X_train_tf_word, Y_train, 2, 'rbf'))\n",
    "print('For linear:', svc_param_selection(X_train_tf_word, Y_train, 2, 'linear'))\n",
    "print('For poly:', svc_param_selection(X_train_tf_word, Y_train, 2, 'poly'))\n",
    "print('For sigmoid:', svc_param_selection(X_train_tf_word, Y_train, 2, 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['rbf'] = svm.SVC(kernel='rbf', C= 10, gamma=0.1)\n",
    "models['linear']  = svm.SVC(kernel='linear', C= 1, gamma=0.001)\n",
    "models['poly']  = svm.SVC(kernel='poly', C= 0.001, gamma=0.001)\n",
    "models['sigmoid'] = svm.SVC(kernel='sigmoid', C= 10, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model rbf\n",
      "Training score: 0.9888888888888889. Test score: 0.6153846153846154\n",
      "For model linear\n",
      "Training score: 0.9888888888888889. Test score: 0.5294117647058824\n",
      "For model poly\n",
      "Training score: 0.5555555555555556. Test score: 0.5217391304347826\n",
      "For model sigmoid\n",
      "Training score: 0.9888888888888889. Test score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "scores = s.run_models(models, X_train_tf_word, Y_train, X_test_tf_word, Y_test)\n",
    "for model in scores:\n",
    "    print('For model', model)\n",
    "    print('Training score: {}. Test score: {}'.format(scores[model]['train'],scores[model]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
