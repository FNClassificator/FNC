{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title similarity Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for Jupyter Notebook\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.fake_news_detector.core.classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0dfbe4f10a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_news_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdoc2vec_classification\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_news_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclean_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.fake_news_detector.core.classification'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.utils import io\n",
    "from src.fake_news_detector.core.classification import doc2vec_classification as dc  \n",
    "from src.fake_news_detector.core.nlp import clean_text as ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset (dataset_content.json)\n",
    "\n",
    "The file `dataset_content.json` contains all tokenize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/dataset_content.json')\n",
    "df = pd.DataFrame(data=articles['articles']) # Put in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adjective_words', 'all_joined', 'all_word', 'common_noun_words',\n",
       "       'conjunction_words', 'fake', 'negative_words', 'noun_phrases_words',\n",
       "       'positive_words', 'subtitle_word', 'title_adjective_words',\n",
       "       'title_common_noun_words', 'title_conjunction_words',\n",
       "       'title_negative_words', 'title_noun_phrases_words',\n",
       "       'title_positive_words', 'title_word', 'verb_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i, row in df.iterrows():\n",
    "    title = ct.clean_text_by_word(row['title'], True)\n",
    "    subtitle = ct.clean_text_by_word(row['subtitle'], True)\n",
    "    text = []\n",
    "    for content in row['text']:\n",
    "        text += ct.clean_text_by_word(content, True)\n",
    "    all_t = title + subtitle + text\n",
    "    documents.append(all_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Thai police have clarified to the middle A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swiss government has said Tuesday that \"a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Government of Navarra, within the Skolae p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carmen Jiménez told her family and friends 28 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lewis Williams, a worker at an engineering fir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              corpus  label\n",
       "0  The Thai police have clarified to the middle A...      1\n",
       "1  The Swiss government has said Tuesday that \"a ...      1\n",
       "2  The Government of Navarra, within the Skolae p...      1\n",
       "3  Carmen Jiménez told her family and friends 28 ...      1\n",
       "4  Lewis Williams, a worker at an engineering fir...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.DataFrame()\n",
    "corpus['corpus'] = df['all_joined']\n",
    "corpus['label'] = df['fake']*1\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DOC2VEC Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f0b5b6cbce61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_doc2vec_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dc' is not defined"
     ]
    }
   ],
   "source": [
    "models = dc.generate_doc2vec_model(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.get_similarty_doc2vec(models, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_1_1 = 0\n",
    "error_1_2 = 0\n",
    "error_2_1 = 0\n",
    "error_2_2 = 0\n",
    "for i, row in corpus.iterrows():\n",
    "    # Model 1 : MAX\n",
    "    if row['result_m1_max'] == 'incorrect':\n",
    "        error_1_1 += 1\n",
    "    # Model 1: MEAN\n",
    "    if row['result_m1_mean'] == 'incorrect':\n",
    "        error_1_2 += 1\n",
    "            # Model 1 : MAX\n",
    "    if row['result_m2_max'] == 'incorrect':\n",
    "        error_2_1 += 1\n",
    "    # Model 1: MEAN\n",
    "    if row['result_m2_mean'] == 'incorrect':\n",
    "        error_2_2 += 1\n",
    "\n",
    "size = len(corpus)\n",
    "print('SIMILARITY TITLE SUBJECT WITH DOC2VEC')\n",
    "print('Model 1: Max Top 3:')\n",
    "print('%error:', error_1_1*100/size)\n",
    "correct_1_1 = size - error_1_1\n",
    "print('%correct:', correct_1_1*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 1: Mean Top 3:')\n",
    "print('%error:', error_1_2*100/size)\n",
    "correct_1_2 = size - error_1_2\n",
    "print('%correct:', correct_1_2*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 2: Max Top 3:')\n",
    "print('%error:', error_2_1*100/size)\n",
    "correct_2_1 = size - error_2_1\n",
    "print('%correct:', correct_2_1*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 2: Mean Top 3:')\n",
    "print('%error:', error_2_2*100/size)\n",
    "correct_2_2 = size - error_2_2\n",
    "print('%correct:', correct_2_2*100/size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
