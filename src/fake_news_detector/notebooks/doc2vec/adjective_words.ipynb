{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title similarity Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for Jupyter Notebook\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.fake_news_detector.core.classification.doc2vec_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-87103bb653ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_news_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/FNC/src/fake_news_detector/core/classification/doc2vec/classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTaggedDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_news_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2vec_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoc2VecModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.fake_news_detector.core.classification.doc2vec_models'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.utils import io\n",
    "from src.fake_news_detector.core.classification.doc2vec import classification as dc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset (dataset_content.json)\n",
    "\n",
    "The file `dataset_content.json` contains all tokenize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/dataset_content.json')\n",
    "df = pd.DataFrame(data=articles['articles']) # Put in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.DataFrame()\n",
    "corpus['corpus'] = df['title_adjective_words']\n",
    "corpus['label'] = df['fake']*1\n",
    "len(df)\n",
    "corpus['id'] = list(range(0,len(df)))\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DOC2VEC Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dc.generate_doc2vec_model(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.get_similarty_doc2vec(models, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_1_1 = 0\n",
    "error_1_2 = 0\n",
    "error_2_1 = 0\n",
    "error_2_2 = 0\n",
    "for i, row in corpus.iterrows():\n",
    "    # Model 1 : MAX\n",
    "    if row['result_m1_max'] == 'incorrect':\n",
    "        error_1_1 += 1\n",
    "    # Model 1: MEAN\n",
    "    if row['result_m1_mean'] == 'incorrect':\n",
    "        error_1_2 += 1\n",
    "            # Model 1 : MAX\n",
    "    if row['result_m2_max'] == 'incorrect':\n",
    "        error_2_1 += 1\n",
    "    # Model 1: MEAN\n",
    "    if row['result_m2_mean'] == 'incorrect':\n",
    "        error_2_2 += 1\n",
    "\n",
    "size = len(corpus)\n",
    "print('SIMILARITY TITLE SUBJECT WITH DOC2VEC')\n",
    "print('Model 1: Max Top 3:')\n",
    "print('%error:', error_1_1*100/size)\n",
    "correct_1_1 = size - error_1_1\n",
    "print('%correct:', correct_1_1*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 1: Mean Top 3:')\n",
    "print('%error:', error_1_2*100/size)\n",
    "correct_1_2 = size - error_1_2\n",
    "print('%correct:', correct_1_2*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 2: Max Top 3:')\n",
    "print('%error:', error_2_1*100/size)\n",
    "correct_2_1 = size - error_2_1\n",
    "print('%correct:', correct_2_1*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 2: Mean Top 3:')\n",
    "print('%error:', error_2_2*100/size)\n",
    "correct_2_2 = size - error_2_2\n",
    "print('%correct:', correct_2_2*100/size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
