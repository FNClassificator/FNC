{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title similarity Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for Jupyter Notebook\n",
    "import sys\n",
    "sys.path.append('/home/elenaruiz/Documents/FNC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.utils import io\n",
    "from src.fake_news_detector.core.classification.doc2vec import classification as dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset (dataset_content.json)\n",
    "\n",
    "The file `dataset_content.json` contains all tokenize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = io.read_json_file('/home/elenaruiz/Documents/FNC/src/data/dataset_content.json')\n",
    "df = pd.DataFrame(data=articles['articles']) # Put in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adjective_words', 'common_noun_words', 'conjunction_words', 'fake',\n",
       "       'negative_words', 'noun_phrases_words', 'positive_words', 'subject',\n",
       "       'title_adjective_words', 'title_common_noun_words',\n",
       "       'title_conjunction_words', 'title_negative_words',\n",
       "       'title_noun_phrases_words', 'title_positive_words', 'title_subject'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[they]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[switzerland]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[navarre]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[a, woman]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          corpus  label  id\n",
       "0         [they]      1   0\n",
       "1  [switzerland]      1   1\n",
       "2      [navarre]      1   2\n",
       "3     [a, woman]      1   3\n",
       "4             []      1   4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.DataFrame()\n",
    "corpus['corpus'] = df['title_subject']\n",
    "corpus['label'] = df['fake']*1\n",
    "len(df)\n",
    "corpus['id'] = list(range(0,len(df)))\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DOC2VEC Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d100,n5,w8,mc19,s0.001,t4)\n",
      "Doc2Vec(dm/m,d100,n5,w8,mc19,s0.001,t4)\n"
     ]
    }
   ],
   "source": [
    "models = dc.generate_doc2vec_model(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d100,n5,w8,mc19,s0.001,t4)\n",
      "Doc2Vec(dm/m,d100,n5,w8,mc19,s0.001,t4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elenaruiz/Documents/FNC/env/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ID: 0 that is  fake and similars are:  1 0 1\n",
      "Checking ID: 1 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 2 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 3 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 4 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 5 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 6 that is  fake and similars are:  1 0 0\n",
      "Checking ID: 7 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 8 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 9 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 10 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 11 that is  fake and similars are:  1 1 1\n",
      "Checking ID: 12 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 13 that is  fake and similars are:  1 1 1\n",
      "Checking ID: 14 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 15 that is  fake and similars are:  0 0 0\n",
      "Checking ID: 16 that is  fake and similars are:  0 1 0\n",
      "Checking ID: 17 that is  fake and similars are:  1 0 0\n",
      "Checking ID: 18 that is  fake and similars are:  1 1 1\n",
      "Checking ID: 19 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 20 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 21 that is  fake and similars are:  1 0 0\n",
      "Checking ID: 22 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 23 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 24 that is  fake and similars are:  1 0 1\n",
      "Checking ID: 25 that is  fake and similars are:  1 0 1\n",
      "Checking ID: 26 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 27 that is  fake and similars are:  0 1 0\n",
      "Checking ID: 28 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 29 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 30 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 31 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 32 that is  fake and similars are:  1 0 0\n",
      "Checking ID: 33 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 34 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 35 that is  fake and similars are:  1 1 1\n",
      "Checking ID: 36 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 37 that is  fake and similars are:  0 1 0\n",
      "Checking ID: 38 that is  fake and similars are:  0 1 0\n",
      "Checking ID: 39 that is  fake and similars are:  1 1 1\n",
      "Checking ID: 40 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 41 that is  fake and similars are:  1 1 1\n",
      "Checking ID: 42 that is  fake and similars are:  1 0 1\n",
      "Checking ID: 43 that is  fake and similars are:  1 0 1\n",
      "Checking ID: 44 that is  fake and similars are:  0 1 0\n",
      "Checking ID: 45 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 46 that is  fake and similars are:  0 0 0\n",
      "Checking ID: 47 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 48 that is  fake and similars are:  1 1 0\n",
      "Checking ID: 49 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 50 that is  fake and similars are:  0 0 1\n",
      "Checking ID: 51 that is  fake and similars are:  1 1 1\n",
      "Checking ID: 52 that is  fake and similars are:  1 0 0\n",
      "Checking ID: 53 that is  fake and similars are:  1 0 1\n",
      "Checking ID: 54 that is  fake and similars are:  0 1 0\n",
      "Checking ID: 55 that is  fake and similars are:  0 1 1\n",
      "Checking ID: 56 that is  real and similars are:  1 0 1\n",
      "Checking ID: 57 that is  real and similars are:  1 1 0\n",
      "Checking ID: 58 that is  real and similars are:  1 0 1\n",
      "Checking ID: 59 that is  real and similars are:  1 1 1\n",
      "Checking ID: 60 that is  real and similars are:  1 1 1\n",
      "Checking ID: 61 that is  real and similars are:  0 0 1\n",
      "Checking ID: 62 that is  real and similars are:  1 1 0\n",
      "Checking ID: 63 that is  real and similars are:  1 1 0\n",
      "Checking ID: 64 that is  real and similars are:  1 1 1\n",
      "Checking ID: 65 that is  real and similars are:  1 1 0\n",
      "Checking ID: 66 that is  real and similars are:  1 0 1\n",
      "Checking ID: 67 that is  real and similars are:  0 0 1\n",
      "Checking ID: 68 that is  real and similars are:  1 1 1\n",
      "Checking ID: 69 that is  real and similars are:  1 1 0\n",
      "Checking ID: 70 that is  real and similars are:  0 1 1\n",
      "Checking ID: 71 that is  real and similars are:  1 0 1\n",
      "Checking ID: 72 that is  real and similars are:  1 0 1\n",
      "Checking ID: 73 that is  real and similars are:  0 1 0\n",
      "Checking ID: 74 that is  real and similars are:  1 0 1\n",
      "Checking ID: 75 that is  real and similars are:  0 1 0\n",
      "Checking ID: 76 that is  real and similars are:  0 1 1\n",
      "Checking ID: 77 that is  real and similars are:  1 1 1\n",
      "Checking ID: 78 that is  real and similars are:  1 0 1\n",
      "Checking ID: 79 that is  real and similars are:  1 1 1\n",
      "Checking ID: 80 that is  real and similars are:  1 1 0\n",
      "Checking ID: 81 that is  real and similars are:  0 0 1\n",
      "Checking ID: 82 that is  real and similars are:  0 0 1\n",
      "Checking ID: 83 that is  real and similars are:  0 1 0\n",
      "Checking ID: 84 that is  real and similars are:  1 0 0\n",
      "Checking ID: 85 that is  real and similars are:  0 1 0\n",
      "Checking ID: 86 that is  real and similars are:  0 0 1\n",
      "Checking ID: 87 that is  real and similars are:  1 0 1\n",
      "Checking ID: 88 that is  real and similars are:  0 1 1\n",
      "Checking ID: 89 that is  real and similars are:  0 1 1\n",
      "Checking ID: 90 that is  real and similars are:  0 1 1\n",
      "Checking ID: 91 that is  real and similars are:  1 0 1\n",
      "Checking ID: 92 that is  real and similars are:  1 0 0\n",
      "Checking ID: 93 that is  real and similars are:  1 0 1\n",
      "Checking ID: 94 that is  real and similars are:  0 0 1\n",
      "Checking ID: 95 that is  real and similars are:  0 0 1\n",
      "Checking ID: 96 that is  real and similars are:  1 1 1\n",
      "Checking ID: 97 that is  real and similars are:  1 1 0\n",
      "Checking ID: 98 that is  real and similars are:  1 0 0\n",
      "Checking ID: 99 that is  real and similars are:  1 0 0\n",
      "Checking ID: 100 that is  real and similars are:  1 0 1\n"
     ]
    }
   ],
   "source": [
    "dc.get_similarty_doc2vec(models, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMILARITY TITLE SUBJECT WITH DOC2VEC\n",
      "Model 1: Max Top 3:\n",
      "%error: 51.48514851485149\n",
      "%correct: 48.51485148514851\n",
      "-------------------------------------\n",
      "Model 1: Mean Top 3:\n",
      "%error: 51.48514851485149\n",
      "%correct: 48.51485148514851\n",
      "-------------------------------------\n",
      "Model 2: Max Top 3:\n",
      "%error: 51.48514851485149\n",
      "%correct: 48.51485148514851\n",
      "-------------------------------------\n",
      "Model 2: Mean Top 3:\n",
      "%error: 51.48514851485149\n",
      "%correct: 48.51485148514851\n"
     ]
    }
   ],
   "source": [
    "error_1_1 = 0\n",
    "error_1_2 = 0\n",
    "error_2_1 = 0\n",
    "error_2_2 = 0\n",
    "for i, row in corpus.iterrows():\n",
    "    # Model 1 : MAX\n",
    "    if row['result_m1_max'] == 'incorrect':\n",
    "        error_1_1 += 1\n",
    "    # Model 1: MEAN\n",
    "    if row['result_m1_mean'] == 'incorrect':\n",
    "        error_1_2 += 1\n",
    "            # Model 1 : MAX\n",
    "    if row['result_m2_max'] == 'incorrect':\n",
    "        error_2_1 += 1\n",
    "    # Model 1: MEAN\n",
    "    if row['result_m2_mean'] == 'incorrect':\n",
    "        error_2_2 += 1\n",
    "\n",
    "size = len(corpus)\n",
    "print('SIMILARITY TITLE SUBJECT WITH DOC2VEC')\n",
    "print('Model 1: Max Top 3:')\n",
    "print('%error:', error_1_1*100/size)\n",
    "correct_1_1 = size - error_1_1\n",
    "print('%correct:', correct_1_1*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 1: Mean Top 3:')\n",
    "print('%error:', error_1_2*100/size)\n",
    "correct_1_2 = size - error_1_2\n",
    "print('%correct:', correct_1_2*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 2: Max Top 3:')\n",
    "print('%error:', error_2_1*100/size)\n",
    "correct_2_1 = size - error_2_1\n",
    "print('%correct:', correct_2_1*100/size)\n",
    "print('-------------------------------------')\n",
    "print('Model 2: Mean Top 3:')\n",
    "print('%error:', error_2_2*100/size)\n",
    "correct_2_2 = size - error_2_2\n",
    "print('%correct:', correct_2_2*100/size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
